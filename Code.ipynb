{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copie de Copie de Copie de Amaury et Baptiste fin de séance 4",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
     {
      "source": [
        "## Exemples de machine learning : projet Seedbank\n",
        "\n",
        "Pour voir des exemples de bout en bout des analyses interactives de machine learning rendues possibles par Colaboratory, découvrez le projet <a href=\"https://research.google.com/seedbank/\">Seedbank</a>.\n",
        "\n",
        "Voici quelques exemples :\n",
        "\n",
        "- <a href=\"https://research.google.com/seedbank/seed/neural_style_transfer_with_tfkeras\">Transfert de style neuronal</a> : utiliser le deep learning pour transférer un style d'une image à une autre.\n",
        "- <a href=\"https://research.google.com/seedbank/seed/ez_nsynth\">EZ NSynth</a> : synthétiser des sons avec les auto-encodeurs WaveNet.\n",
        "- <a href=\"https://research.google.com/seedbank/seed/fashion_mnist_with_keras_and_tpus\">Fashion MNIST avec Keras et TPU</a> : classer des images liées à la mode en utilisant le deep learning.\n",
        "- <a href=\"https://research.google.com/seedbank/seed/deepdream\">DeepDream</a> : produire des images DeepDream à partir de vos propres photos.\n",
        "- <a href=\"https://research.google.com/seedbank/seed/convolutional_vae\">Auto-encodeur variationnel convolutif</a> : créer un modèle génératif de chiffres manuscrits."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qcNHuUJTFjoT"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import math as ma \n",
        "import numpy.random as rd\n",
        "import sklearn.neural_network as nn #not used \n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, MaxPooling2D, SeparableConv2D\n",
        "from keras.layers import Flatten, Dense #not used \n",
        "from keras.applications.vgg16 import VGG16 #not used\n",
        "from keras.preprocessing.image import load_img, img_to_array\n",
        "from keras.applications.vgg16 import preprocess_input #not used\n",
        "from numpy import zeros, newaxis\n",
        "import statistics\n",
        "from statistics import mean"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4oa62mo-dm5i"
      },
      "source": [
        "#importation des valeurs\n",
        "N=30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xx_Cpo76F1hi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a81b994c-004e-4dfc-a7ae-fd4da17a856f"
      },
      "source": [
        "def init (N): # we initialize an array randomly filled with -1; 0 and 1\n",
        "  a=0\n",
        "  T=np.zeros ((N,N)) # creation of a table of dimension 2 and size NxN\n",
        "  for i in range (N):\n",
        "    for j in range (N): \n",
        "      a= rd.randint (-1,2) # we fill this table with a random value -1, 0 or 1\n",
        "      T[i,j]=a\n",
        "  return(T)\n",
        "\n",
        "T0 =init(30) \n",
        "#print(T0)\n",
        "\n",
        "def listeT0 (N): # The purpose of this function is to create a list of K start tables. \n",
        "  L0=[]\n",
        "  for k in range (1000): # Here the list will be composed of K = 1000 tables\n",
        "    L0.append(init(N))  # These tables will conform to the previous init function\n",
        "  return(L0)\n",
        "\n",
        "L0= listeT0 (N) # We call this list of starting tables L0 (important for the continuation)\n",
        "print(len(L0))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ZpuC4ZCINoG",
        "outputId": "3c8d0504-e60c-4c9f-a49e-a5309f020676",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def evolution (T,N): # This function is the function corresponding to the rule and which makes a table evolve to the following stage \n",
        "  M=np.zeros ((N,N)) # creation of a table of dimension 2 and size N.N\n",
        "  a=0\n",
        "  b=0\n",
        "  for i in range (N): # we go through the table with distinction of the cases to modify the boxes to carry out...\n",
        "    for j in range (N): #... an evolution\n",
        "      if i>0 and i<N-1 and j>0 and j<N-1: # center boxes\n",
        "        a=T[i,j]+T[i+1,j]+T[i-1,j]+T[i,j+1]+T[i,j-1]+T[i+1,j+1]+T[i+1,j-1]+T[i-1,j+1]+T[i-1,j-1]\n",
        "      if i==0 and j!=0 and j!=N-1: # first line \n",
        "        a=T[i,j]+T[i+1,j]+T[i,j+1]+T[i,j-1]+T[i+1,j+1]+T[i+1,j-1]\n",
        "      if i==N-1 and j!=0 and j!=N-1: # last line\n",
        "        a=T[i,j]+T[i-1,j]+T[i,j+1]+T[i,j-1]+T[i-1,j+1]+T[i-1,j-1]\n",
        "      if j==0 and i!=0 and i!=N-1: # first column\n",
        "        a=T[i,j]+T[i+1,j]+T[i-1,j]+T[i,j+1]+T[i+1,j+1]+T[i-1,j+1]\n",
        "      if j==N-1 and i!=0 and i!=N-1: # last column\n",
        "        a=T[i,j]+T[i+1,j]+T[i-1,j]+T[i,j-1]+T[i+1,j-1]+T[i-1,j-1]\n",
        "      if i==0 and j==0: # angle 1 (top left)\n",
        "        a=T[i,j]+T[i+1,j]+T[i,j+1]+T[i+1,j+1]\n",
        "      if i==0 and j==N-1: # angle 2 (top right)\n",
        "        a=T[i,j]+T[i+1,j]+T[i,j-1]+T[i+1,j-1]\n",
        "      if i==N-1 and j==0: # angle 3 (bottom left)\n",
        "        a=T[i,j]+T[i-1,j]+T[i,j+1]+T[i-1,j+1]\n",
        "      if i==N-1 and j==N-1: # angle 4 (bottom right)\n",
        "        a=T[i,j]+T[i-1,j]+T[i,j-1]+T[i-1,j-1]\n",
        "      if a==0: # simple ...   \n",
        "        b=0\n",
        "      elif a<0:            # ... representaion ...\n",
        "        b=-1\n",
        "      elif a>0:                                   # ... of the instructions\n",
        "        b=1\n",
        "      M[i,j]=b   # we modify the value of the cell according to the value of the sum\n",
        "  return (M)\n",
        "\n",
        "M0= evolution (T0,30)\n",
        "print (T0)\n",
        "print (M0)\n",
        "\n",
        "def listeT2 (L0,N): # we create the list of tables having undergone a single evolution from the list L0.\n",
        "  L2=[]\n",
        "  for k in L0:\n",
        "    L2.append(evolution(k,N))\n",
        "  return (L2)\n",
        "\n",
        "L2 = listeT2 (L0,30) # On appelle L2 cette liste de tableau de dépar (important pour la suite)\n",
        "#print (L2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.  0.  0. -1.  1. -1.  1.  1.  1.  1.  0.  1.  0.  0. -1.  0.  1. -1.\n",
            "   1. -1.  0.  1.  0.  1.  0. -1.  1.  0.  0. -1.]\n",
            " [-1.  1. -1.  0.  0.  0.  0.  0.  1.  0.  0. -1. -1.  0.  1.  1. -1.  1.\n",
            "  -1.  1.  1.  1.  0.  1. -1.  1.  0.  1.  0.  1.]\n",
            " [ 1.  1.  1.  0. -1.  1.  1.  0.  0.  0.  0. -1.  1. -1.  0.  0.  0.  0.\n",
            "  -1. -1. -1.  1.  1.  0.  1.  0.  1. -1.  1. -1.]\n",
            " [-1. -1.  1. -1. -1.  0. -1. -1.  1.  0. -1. -1. -1.  1. -1.  0. -1.  0.\n",
            "   0. -1. -1.  0.  0.  0.  1. -1.  0.  1. -1.  1.]\n",
            " [ 0. -1.  0.  1.  0.  1. -1. -1.  1.  0. -1.  0.  1. -1.  0. -1. -1.  1.\n",
            "   0. -1.  0. -1. -1.  1.  1. -1. -1. -1. -1. -1.]\n",
            " [ 0.  1. -1.  0.  1.  0.  1.  0.  1. -1.  0.  1. -1.  0. -1. -1.  0. -1.\n",
            "   1.  0.  1. -1.  0.  1. -1.  1.  1.  1. -1. -1.]\n",
            " [ 1. -1.  0.  0.  0. -1.  0.  0.  1.  1.  1. -1.  0.  0.  0.  1.  1.  0.\n",
            "   1. -1.  1.  0.  0. -1. -1.  0.  1.  1. -1.  1.]\n",
            " [ 0.  1. -1.  1.  1.  0.  0. -1.  0.  1.  1.  0.  1. -1.  1.  0.  0.  0.\n",
            "  -1.  0.  0.  0.  0.  0. -1.  1. -1.  0.  0. -1.]\n",
            " [ 0. -1.  0.  0.  0.  1. -1.  1.  1.  0. -1.  1.  0.  1.  0.  0.  0. -1.\n",
            "   0.  1. -1. -1.  0.  0.  1.  1. -1.  0.  1. -1.]\n",
            " [-1.  1.  1.  1.  1. -1.  1. -1.  0.  1.  1.  1.  1.  0.  1.  1.  1.  0.\n",
            "   0. -1.  0. -1.  1.  0. -1. -1.  1.  0.  0.  0.]\n",
            " [ 0. -1.  0. -1.  1.  0. -1.  0. -1. -1.  0.  1.  0.  0. -1.  0.  1.  1.\n",
            "  -1.  0. -1.  0.  0. -1. -1.  1.  1.  0.  1.  0.]\n",
            " [-1.  0.  1.  1. -1. -1.  0.  1.  1.  1.  0.  1. -1.  1.  0.  1. -1.  0.\n",
            "   0.  1.  0.  0.  0. -1.  0.  0.  1. -1. -1. -1.]\n",
            " [ 0.  1.  1.  0. -1.  1. -1.  0.  1.  0.  0.  0.  0. -1.  0.  1.  0.  0.\n",
            "   1.  0. -1.  1.  1.  0. -1.  0.  1. -1. -1.  1.]\n",
            " [ 0.  1.  0. -1.  1.  1.  1. -1.  0.  1.  0. -1. -1. -1.  1. -1. -1.  1.\n",
            "   0.  0.  1.  0.  0.  0. -1.  1.  1. -1.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0.  1.  0.  0. -1.  0.  1. -1.  0.  1.  0.  0.  1. -1.\n",
            "   1. -1. -1.  0. -1.  0. -1.  0.  1.  0.  1.  1.]\n",
            " [ 0.  1.  1.  0. -1.  0. -1.  1. -1. -1.  1.  0.  0. -1.  0.  0.  0.  0.\n",
            "   0.  0.  1.  1. -1. -1.  0.  0.  1.  0. -1.  1.]\n",
            " [ 1. -1.  0. -1. -1.  1. -1. -1. -1. -1.  0.  0. -1.  0. -1. -1. -1.  1.\n",
            "   0.  0.  1.  0.  1.  1. -1. -1.  1. -1. -1.  0.]\n",
            " [ 1.  0.  0.  1.  1.  1.  0. -1.  0.  1.  1. -1.  1. -1.  0. -1.  0.  0.\n",
            "  -1.  1. -1.  0. -1. -1.  0. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  0.  0.  0.  1.  1.  1. -1. -1.  1.  0. -1.  0.  0.  0.  1.  0.\n",
            "   1.  1.  0.  0.  0.  0.  0.  1. -1.  1.  1.  0.]\n",
            " [ 1.  0.  0.  0. -1.  1.  0.  0.  1. -1.  1. -1. -1.  1.  1.  0.  0.  0.\n",
            "   1.  0.  1.  1. -1.  0. -1.  1.  1. -1.  0.  0.]\n",
            " [ 0.  0. -1.  1.  0. -1. -1. -1.  0.  0. -1.  0. -1.  0. -1.  1.  0.  1.\n",
            "  -1.  0. -1.  1. -1. -1. -1.  0. -1.  0.  0.  0.]\n",
            " [-1.  0. -1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0. -1.  0. -1.\n",
            "   0.  0.  1.  0.  1.  1. -1. -1.  1.  0.  1.  0.]\n",
            " [-1. -1. -1. -1. -1.  0.  0.  1. -1.  0. -1. -1.  1.  1.  1. -1.  0.  0.\n",
            "   1. -1. -1.  0. -1.  1.  1. -1.  0.  0.  0.  1.]\n",
            " [ 1.  0.  1.  0.  1. -1. -1.  1.  0.  1.  0. -1.  1.  1. -1.  1.  1.  0.\n",
            "  -1.  1. -1.  1.  1. -1.  1. -1.  0. -1. -1. -1.]\n",
            " [ 0.  0. -1.  0.  1.  1.  0.  1. -1. -1.  0. -1.  1. -1.  1. -1.  1. -1.\n",
            "   1.  0. -1.  0. -1. -1. -1. -1. -1.  1.  1.  0.]\n",
            " [ 0.  1. -1.  1. -1. -1. -1.  0.  1.  0.  1.  1.  0.  1. -1.  0.  0.  0.\n",
            "   0. -1. -1.  1. -1.  0.  0. -1.  0.  1.  1.  0.]\n",
            " [ 1.  0.  1.  1.  0.  1. -1.  1.  1.  1.  1.  0. -1.  1.  1.  0.  1.  1.\n",
            "   0.  0.  0. -1.  1. -1. -1. -1.  1. -1.  1.  0.]\n",
            " [ 0. -1. -1.  1.  0.  1.  1.  1. -1. -1. -1.  0.  0.  1. -1.  1. -1.  1.\n",
            "  -1.  0. -1. -1.  1. -1. -1.  0. -1.  0.  0. -1.]\n",
            " [ 1.  1.  1.  1.  1.  0.  0.  0.  1.  0. -1.  0. -1. -1.  0.  0. -1. -1.\n",
            "  -1.  0. -1.  1. -1.  1. -1.  0.  0.  0. -1.  0.]\n",
            " [ 0. -1. -1.  0. -1.  0.  1. -1. -1.  0.  1.  0. -1.  1. -1.  0.  1.  1.\n",
            "   0. -1.  0.  1.  0.  1.  1.  0. -1. -1.  0.  0.]]\n",
            "[[-1. -1. -1. -1. -1.  1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  1.  1.  0.\n",
            "   0.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.  0.]\n",
            " [ 1.  1.  1. -1. -1.  1.  1.  1.  1.  1.  0. -1. -1. -1.  0.  1.  1. -1.\n",
            "  -1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  0.]\n",
            " [ 0.  1.  1. -1. -1. -1.  0.  1.  1.  1. -1. -1. -1. -1.  1. -1.  0. -1.\n",
            "  -1. -1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.]\n",
            " [-1.  1.  1.  0.  0. -1. -1. -1.  0.  0. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            "  -1. -1. -1. -1.  1.  1.  1.  1. -1. -1. -1. -1.]\n",
            " [-1. -1. -1.  0.  1.  0. -1.  0.  0.  0. -1. -1. -1. -1. -1. -1. -1. -1.\n",
            "  -1. -1. -1. -1. -1.  1.  1.  0.  0. -1. -1. -1.]\n",
            " [ 0. -1. -1.  1.  1.  1. -1.  1.  1.  1.  0.  0. -1. -1. -1. -1. -1.  1.\n",
            "   0.  1. -1. -1. -1. -1.  0.  0.  1. -1. -1. -1.]\n",
            " [ 1.  0.  0.  1.  1.  1. -1.  1.  1.  1.  1.  1. -1. -1. -1.  1.  0.  1.\n",
            "  -1.  1.  0.  1. -1. -1. -1.  0.  1.  1. -1. -1.]\n",
            " [ 0. -1. -1.  1.  1.  0. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.\n",
            "  -1.  0. -1. -1. -1. -1.  0.  0.  1.  0.  0. -1.]\n",
            " [ 0.  0.  1.  1.  1.  1. -1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1. -1.\n",
            "  -1. -1. -1. -1. -1.  0.  0. -1.  0.  0. -1. -1.]\n",
            " [-1. -1.  0.  1.  1.  1. -1. -1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1.  1.]\n",
            " [-1.  0.  1.  1.  0. -1. -1.  0.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "   0. -1. -1. -1. -1. -1. -1.  1.  1.  1. -1. -1.]\n",
            " [-1.  1.  1.  1. -1. -1. -1.  0.  1.  1.  1.  1.  1. -1.  1.  1.  1.  1.\n",
            "   1. -1.  0.  0.  0. -1. -1.  1.  1.  0. -1. -1.]\n",
            " [ 1.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1. -1. -1. -1.  1.  0.  0.  0.\n",
            "   1.  1.  1.  1.  1. -1. -1.  1.  1. -1. -1. -1.]\n",
            " [ 1.  1.  1.  1.  1.  1.  1. -1.  0.  1.  0. -1. -1. -1.  0.  1.  0.  1.\n",
            "   1.  0. -1.  0.  1. -1. -1.  1.  1.  1.  0.  1.]\n",
            " [ 1.  1.  1.  1.  1.  1.  1. -1. -1.  0.  0. -1. -1. -1. -1.  0. -1.  1.\n",
            "   0.  1.  1.  0. -1. -1. -1.  1.  1.  1.  1.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  0. -1. -1. -1. -1.  0. -1. -1. -1. -1. -1.  1.\n",
            "   0.  1.  1.  1.  0. -1. -1.  0.  1.  1.  0.  1.]\n",
            " [ 1.  1.  1.  0.  1. -1. -1. -1. -1. -1.  0.  1. -1. -1. -1. -1. -1. -1.\n",
            "   1.  1.  1.  1. -1. -1. -1.  0.  0. -1. -1. -1.]\n",
            " [ 1.  1.  0.  0.  1.  1.  1. -1. -1. -1.  0.  0. -1. -1. -1. -1. -1.  1.\n",
            "   1.  1.  1.  0.  0. -1. -1. -1.  0.  0. -1. -1.]\n",
            " [ 1.  1.  1.  1.  1.  1.  1.  1. -1.  1.  0.  0. -1.  0.  0.  1.  0.  1.\n",
            "   1.  1.  1. -1. -1. -1. -1.  1.  1.  1. -1. -1.]\n",
            " [ 1.  0.  1. -1.  1.  0.  1.  0. -1. -1. -1. -1. -1. -1.  1.  1.  1.  1.\n",
            "   1.  1.  1.  0. -1. -1. -1. -1.  1.  0.  1.  1.]\n",
            " [ 0. -1. -1. -1.  1. -1. -1. -1. -1.  0. -1. -1.  0.  0.  1.  0.  0.  0.\n",
            "   0.  1.  1.  1.  1. -1. -1. -1.  0.  1.  0.  1.]\n",
            " [-1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  0. -1. -1.  0.\n",
            "  -1. -1. -1. -1.  1. -1. -1. -1. -1.  1.  1.  1.]\n",
            " [-1. -1. -1. -1. -1. -1.  1.  0.  1. -1. -1.  1.  1.  1.  1.  0. -1.  0.\n",
            "  -1. -1.  0.  1.  1.  1. -1. -1. -1.  0. -1.  0.]\n",
            " [-1. -1. -1. -1.  0.  0.  1.  0.  1. -1. -1. -1.  1.  1.  1.  1.  0.  1.\n",
            "   0. -1. -1. -1. -1. -1. -1. -1. -1. -1.  0.  0.]\n",
            " [ 1.  1.  1.  1.  1. -1. -1.  0.  1.  1.  0.  1.  1.  1.  0.  1.  1.  1.\n",
            "  -1. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  0.]\n",
            " [ 1.  1.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "   0. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.]\n",
            " [ 1.  0.  1.  1.  1. -1.  1.  1.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.\n",
            "   0. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  1.]\n",
            " [ 1.  1.  1.  1.  1.  1.  1.  1.  1.  0. -1. -1. -1. -1.  1.  0.  1. -1.\n",
            "  -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
            " [ 0. -1.  0.  1.  1.  1.  1.  1. -1. -1. -1. -1. -1. -1.  0. -1.  1. -1.\n",
            "  -1. -1. -1. -1.  1.  0.  0. -1. -1. -1. -1. -1.]\n",
            " [ 1.  1.  1.  1.  1.  1.  0.  0. -1.  0.  0. -1. -1. -1. -1. -1.  0. -1.\n",
            "  -1. -1.  0.  0.  1.  1.  1. -1. -1. -1. -1. -1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "951jjy8iePZt"
      },
      "source": [
        "def fonction (T,N): # We make the table evolve until the final state\n",
        "  T1= T\n",
        "  a=0\n",
        "  for i in range (10000): # the final state is reached each time well before 10000 evolutions\n",
        "    T1= evolution (T,N)\n",
        "    if (T==T1).all()== True: # we get out of the loop as soon as 2 evolutions in a row are identical (= the array will not evolve anymore)\n",
        "      a=i\n",
        "      break\n",
        "    else: \n",
        "      T=T1\n",
        "  return (T1) # we return the final table (we see that the result converges all the time)\n",
        "\n",
        "T2= fonction (T0,30)\n",
        "#print (T0)\n",
        "#print (T2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aDi0LDzPgkwL",
        "outputId": "41e61e07-69ff-477b-8a8f-7f027636596b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "source": [
        "def MtoIm(M,N):\n",
        "  im=np.zeros ((N,N,3))\n",
        "  for x in range (N):\n",
        "    for y in range (N):\n",
        "      if M[x][y]==-1:\n",
        "        im[x,y,:]=[1,0,0]\n",
        "      elif M[x,y]==0:\n",
        "        im[x,y,:]= [0,0,0]\n",
        "      elif M[x,y]==1:\n",
        "        im[x,y,:]=[0,1,0]\n",
        "  return (im)\n",
        "\n",
        "im = MtoIm(T0,30)    # we display the tables with the color code (initial state/end state)\n",
        "plt.imshow(im)\n",
        "plt.show()\n",
        "\n",
        "im2 = MtoIm(T2,30)\n",
        "plt.imshow(im2)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n6xDWFPQAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nVwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4sZNNiBYZ-c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9fecfb70-6b1b-4160-e5ad-8606c312f9b4"
      },
      "source": [
        "def shapem(L0,L2):# The purpose of this function is to transform the starting list and the evolved list into arrays of compatible dimensions\n",
        "  L1=[]\n",
        "  L4=[]\n",
        "  for k in L0:\n",
        "    k=k.reshape((N,N,1)) # We transform all the tables, then of dimension 2, of the two lists into tables of dimension 3\n",
        "    L1.append(k)\n",
        "  for i in L2:\n",
        "    i=i.reshape((N,N,1))\n",
        "    L4.append(i)\n",
        "  L1=np.stack(L1) # with the stack function we have L1.shape =(1000, 30, 30, 1)\n",
        "  L4=np.stack(L4)\n",
        "  return (L1,L4)\n",
        "\n",
        "L1,L4=shapem (L0,L2) # L1 and L4 are the compatible versions of L0 and L2 with Conv2D\n",
        "print (L1.shape)\n",
        "print (L1[24].shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 30, 30, 1)\n",
            "(30, 30, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "outputId": "3c1c0da2-356e-4411-b4bd-cf369a379181",
        "id": "k4BWG8i1xG1l",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rnvide = Sequential() # We create our neural network\n",
        "Depay=Conv2D(1, (3, 3), input_shape=(N, N, 1) , padding='same', activation='tanh') # a convolution with 1 filter of dimension 3.3\n",
        "rnvide.add(Depay)\n",
        "\n",
        "#we train our neural network with tables having undergone 1 evolution\n",
        "\n",
        "rnvide.compile(loss='mse', optimizer='adadelta', metrics=['accuracy'])\n",
        "rnvide.fit(x=L1, y=L4, batch_size=64, epochs=100, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
        "\n",
        "\n",
        "Weight=np.zeros((3,3)) # we get the filter weights of our convolution\n",
        "for i in range (3):\n",
        "  for j in range (3):\n",
        "    Weight [i][j]=float (Depay.get_weights()[0][i][j][0])\n",
        "print (Weight)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 0s 147us/step - loss: 1.1300 - acc: 0.3024\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 1.0719 - acc: 0.3211\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 1.0156 - acc: 0.3390\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.9614 - acc: 0.3565\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.9091 - acc: 0.3741\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.8586 - acc: 0.3906\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 0s 43us/step - loss: 0.8097 - acc: 0.4067\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.7622 - acc: 0.4228\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 0s 43us/step - loss: 0.7158 - acc: 0.4391\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.6705 - acc: 0.4539\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.6262 - acc: 0.4676\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.5831 - acc: 0.4819\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 0s 44us/step - loss: 0.5414 - acc: 0.4958\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 0s 58us/step - loss: 0.5014 - acc: 0.5123\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.4636 - acc: 0.5238\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.4283 - acc: 0.5420\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.3959 - acc: 0.5581\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.3666 - acc: 0.5728\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.3401 - acc: 0.5916\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.3164 - acc: 0.6080\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.2951 - acc: 0.6221\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.2759 - acc: 0.6379\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 0s 67us/step - loss: 0.2586 - acc: 0.6534\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 0s 68us/step - loss: 0.2429 - acc: 0.6684\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.2286 - acc: 0.6844\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.2154 - acc: 0.6976\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.2034 - acc: 0.7093\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.1922 - acc: 0.7216\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1820 - acc: 0.7349\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.1724 - acc: 0.7466\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1635 - acc: 0.7573\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1553 - acc: 0.7659\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.1475 - acc: 0.7741\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.1402 - acc: 0.7818\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.1334 - acc: 0.7897\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.1270 - acc: 0.7969\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1209 - acc: 0.8038\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.1151 - acc: 0.8120\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1097 - acc: 0.8201\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 0s 62us/step - loss: 0.1046 - acc: 0.8295\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.0997 - acc: 0.8384\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 0s 64us/step - loss: 0.0950 - acc: 0.8488\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.0906 - acc: 0.8593\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.0864 - acc: 0.8696\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.0824 - acc: 0.8825\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.0786 - acc: 0.8946\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.0750 - acc: 0.9082\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.0716 - acc: 0.9202\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.0683 - acc: 0.9319\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.0651 - acc: 0.9431\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.0621 - acc: 0.9525\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.0593 - acc: 0.9631\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.0565 - acc: 0.9737\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 0s 57us/step - loss: 0.0539 - acc: 0.9821\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 0s 66us/step - loss: 0.0514 - acc: 0.9883\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.0490 - acc: 0.9915\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.0468 - acc: 0.9944\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.0446 - acc: 0.9977\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.0425 - acc: 0.9997\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.0405 - acc: 1.0000\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 0s 63us/step - loss: 0.0386 - acc: 1.0000\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.0368 - acc: 1.0000\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.0351 - acc: 1.0000\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.0335 - acc: 1.0000\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.0319 - acc: 1.0000\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.0304 - acc: 1.0000\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 0s 44us/step - loss: 0.0290 - acc: 1.0000\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.0276 - acc: 1.0000\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.0263 - acc: 1.0000\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.0250 - acc: 1.0000\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.0238 - acc: 1.0000\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.0227 - acc: 1.0000\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.0216 - acc: 1.0000\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.0206 - acc: 1.0000\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.0196 - acc: 1.0000\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.0187 - acc: 1.0000\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.0178 - acc: 1.0000\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.0169 - acc: 1.0000\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.0161 - acc: 1.0000\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.0153 - acc: 1.0000\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 0s 65us/step - loss: 0.0146 - acc: 1.0000\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.0139 - acc: 1.0000\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 0s 55us/step - loss: 0.0132 - acc: 1.0000\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.0126 - acc: 1.0000\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.0120 - acc: 1.0000\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.0114 - acc: 1.0000\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.0109 - acc: 1.0000\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.0103 - acc: 1.0000\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.0098 - acc: 1.0000\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.0094 - acc: 1.0000\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 0s 57us/step - loss: 0.0089 - acc: 1.0000\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.0085 - acc: 1.0000\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.0081 - acc: 1.0000\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.0077 - acc: 1.0000\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.0073 - acc: 1.0000\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.0070 - acc: 1.0000\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.0066 - acc: 1.0000\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.0063 - acc: 1.0000\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.0060 - acc: 1.0000\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.0057 - acc: 1.0000\n",
            "[[1.31761837 1.30283499 1.31763852]\n",
            " [1.317976   1.31723094 1.30822229]\n",
            " [1.29700232 1.31611335 1.31738198]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLAn1uAjQS-4",
        "outputId": "f2c32737-4719-4e66-dc39-72dbd0bafa83",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "def listeT25 (N):\n",
        "  L0=[]\n",
        "  for k in range (3):\n",
        "    L0.append(init(N))\n",
        "  return(L0)\n",
        "\n",
        "L25=listeT25 (N)\n",
        "#print (L25)\n",
        "\n",
        "L26 = listeT2 (L25,30)\n",
        "\n",
        "L27,L28=shapem (L25,L26) # L27 and L28 simply serve as a master list to test the prediction\n",
        "\n",
        "print (L27.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3, 30, 30, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qGJpHA7YVahB",
        "outputId": "f8fe3e94-079e-4258-87b3-05e7c33a9394",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "H=rnvide.predict(L27, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
        "# We call H the prediction of a table according to the trained network above\n",
        "\n",
        "print (H[1].shape)\n",
        "print (H[1][2][2][0])\n",
        "\n",
        "H1=np.around(H) # We round the values of H to be compatible with the game and the display\n",
        "\n",
        "print (H1[1][2][2][0])\n",
        " \n",
        "for k in range (3): # we test the neural network by visually comparing the prediction of the evolution \n",
        "  im30 = MtoIm(L28[k],30)  # and the real evolution\n",
        "  plt.imshow(im30)\n",
        "  plt.show()\n",
        "\n",
        "  im31 = MtoIm(H1[k],30)\n",
        "  plt.imshow(im31)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(30, 30, 1)\n",
            "0.9875464\n",
            "1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHUiCsANJEHYgCcIOJPG/1nuaUw/n8VsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nHUiCsANJEHYgCcIOJPG/1nuaUw/n8VsAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngST+F5N79MGV2jt3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAO00lEQVR4nO3dT8wc9X3H8c+nhFyAgynUeuSYOkVc\nohxMvUKViiqqKhH1xXBB8aFypUrOIUgg9VCUHOJjVAFVT0hOseJWKVEkkmJFqAm1kOgp4nmQa/yn\nDSQyiq0HG8QBOCXAt4cdtw/O7m8e5rezM/t83y9p5H1mn5n57m+fj2d3vzszjggB2Pl+b+gCACwH\nYQeSIOxAEoQdSIKwA0kQdiCJz9UsbPtBSf8o6SZJ/xQR3yn+/h0O7avZ4mId2OhnvcXVHigv20dN\nGy3bLC88/66a1RY3WbHiruNX85z1MUatD2Peii9J8W541l3u2me3fZOkX0j6iqTLkl6VdDgiLsxd\nZuLQeqfN9WL2kNQrrrZluPuoyTVfpSjU09c3NGrq7Tp+Nc9ZH2PU+jDmrXgixfrsUah5GX+fpDcj\n4lcR8RtJP5B0qGJ9AHpUE/Y9kn695efLzTwAI9T7B3S2j9pet72ud/reGoB5asJ+RdLeLT9/oZn3\nKRFxPCImETHRnRVbA1ClJuyvSrrH9hdtf17S1ySdWkxZABatc+stIj6y/aikn2raejsREecXVtmi\njPAT9+J6x3YQYqEet4ztEA+lVFKpntJ9nT8ZV/sYdVlnV1V99oh4UdKLC6oFQI/4Bh2QBGEHkiDs\nQBKEHUiCsANJEHYgiarW22d1YENaX/JRSYO0rSt6+70dJdV1o10b12rpMff1xFQ1zHswonrYswNJ\nEHYgCcIOJEHYgSQIO5AEYQeSWGrrrUaxU7Nih7F23uYAK+3r0M/ONY3tEOAaPZ0IdB727EAShB1I\ngrADSRB2IAnCDiRB2IEkVqb1NjZjvE7cSunalmsb9x7GqO25HuSMwIVrvc3Dnh1IgrADSRB2IAnC\nDiRB2IEkCDuQhCO69w1sX5L0gaSPJX0UEYUP/iVPHFrvurH5d/V0vsSizp23ndQ+60tNW7N08tEB\nTjjZW1uulIeY/UgX0Wf/84h4dwHrAdAjXsYDSdSGPST9zPaG7aOLKAhAP2pfxt8fEVds/4Gkl2z/\nd0S8svUXmv8Epv8R3FW5NQCdVX1A96kV2cckfRgRT879HT6g4wO67eADum2seP5d8z6g6/wy3vYt\ntm+7flvSVyWd67o+AP2qeRm/W9KPPb2g1+ck/WtE/PtCqgKwcAt7Gb+tjbn7i5ohXv2mOdx0hdQc\nbjq6l/F9vMecSLG+4JfxAFYLYQeSIOxAEoQdSIKwA0kQdiCJpZ5d9oA09wt0bV2Rvr4JV9LHdQlH\naWwXWawZ3CHaax2Xq/r74sKOAOYh7EAShB1IgrADSRB2IAnCDiSx1Nbbhgodg7Y2zsh6XYMcQVW6\ns6IN1nVRD3CRxaqTQfT1nHWsqeqxcGFHAPMQdiAJwg4kQdiBJAg7kARhB5JYauuteNhbC87vWHF+\n/IHaln1st68D4qq6YIUVd22Xdh270pVV2bMDSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBKtYbd9wvY1\n2+e2zLvd9ku232j+3dVvmdPDAedO6jiV1rmDGvttj3OIMej6fLavuGbhbjpvcsm1bmfP/j1JD94w\n7wlJpyPiHkmnm58BjFhr2CPiFUnv3TD7kKSTze2Tkh5acF0AFqzre/bdEbHZ3H5b0u55v2j7qO11\n2+t6p+PWAFSr/oAuIkKFb/lGxPGImETERHfWbg1AV13DftX2miQ1/15bXEkA+tA17KckHWluH5H0\nwmLKAdAXT1+FF37Bfk7SA5LukHRV0rcl/ZukH0q6S9Jbkh6JiBs/xPsdEzs6HuHai9YORw+HIA6h\n5nGWFh6iO1lzQttiK7Hm+NeOy/bxNzSRtB6z19x6PHtEHJ5z11/UFAVgufgGHZAEYQeSIOxAEoQd\nSIKwA0ks9+yyPencwajoHZXaOKvUlmvVtV1VoeoClqWFO7YRq1qXpfVWbLTLJtmzA0kQdiAJwg4k\nQdiBJAg7kARhB5LYEa23oh104siuWodgZK3CmjZY55NkltpyFePTuY3Y8jjmrrdwZUf27EAShB1I\ngrADSRB2IAnCDiRB2IEkCDuQxGj67DVnDR1bL723CyKO7Eyvg6j6QxnAiOphzw4kQdiBJAg7kARh\nB5Ig7EAShB1IojXstk/Yvmb73JZ5x2xfsX2mmQ7WFhIt09iEu01qm4obnT91XeWq2Ul/J8u2nT37\n9yQ9OGP+P0TE/mZ6cbFlAVi01rBHxCuSWi/HDGDcat6zP2r7bPMyf9fCKgLQi65hf0bS3ZL2S9qU\n9NS8X7R91Pa67fV3Om4MQL1OYY+IqxHxcUR8Ium7ku4r/O7xiJhExOTOrlUCqNYp7LbXtvz4sKRz\n834XwDi0HvVm+zlJD0i6w/ZlSd+W9IDt/Zp2Oy5J+nptIVWdiNLCFRdg7KM7UnOm1+LRdANcgHHl\n9HUhyjH2/GZoDXtEHJ4x+9keagHQI75BByRB2IEkCDuQBGEHkiDsQBKEHUhiNGeXbWtVdr4aZmmd\nNf3RUj+8sFjNJoc4LHJsqp6zwrLF56xl3Pt4Xvro3bNnB5Ig7EAShB1IgrADSRB2IAnCDiSx1Nbb\nxgHJ63PuXLEL9nVujQzQPmurdWwtvbEdMtrX+C37cbJnB5Ig7EAShB1IgrADSRB2IAnCDiQxmqPe\nWhXaG8UTq65YG2eQ1lzhvpENX52uY9syCKsyfuzZgSQIO5AEYQeSIOxAEoQdSIKwA0m0ht32Xtsv\n275g+7ztx5r5t9t+yfYbzb+7Wre2oWmfYtbUJuZP81Y5soO5qhWGoDjVrNiFadV0Hr/SH5jLC49p\n/LazZ/9I0t9GxJck/Ymkb9j+kqQnJJ2OiHsknW5+BjBSrWGPiM2IeK25/YGki5L2SDok6WTzaycl\nPdRXkQDqfab37Lb3SbpX0s8l7Y6IzeautyXtXmhlABZq21+XtX2rpOclPR4R79v//444IsKe/S7E\n9lFJR2sLBVBnW3t22zdrGvTvR8SPmtlXba81969JujZr2Yg4HhGTiJgsomAA3Wzn03hLelbSxYh4\nestdpyQdaW4fkfTC4ssDsCiOKPcAbN8v6T8lvS7pk2b2NzV93/5DSXdJekvSIxHxXsu6ujccioe2\ndVxujDoe3VdcZU9j0NeJKsdWb+tiY/obm0ixPvuRtoZ9kTxxaN7ZZatW3G2xvh55XxeMXLWwd/0/\neHRhH1OY2xTCzjfogCQIO5AEYQeSIOxAEoQdSIKwA0kstfU2saPrdR376JON7YKGQxmitVQa+97q\n2SFnKJZUfixB6w1IjbADSRB2IAnCDiRB2IEkCDuQxFIv7LhxQHLXo956OIy1raWySq25VWsPDTK0\nhTHyCj3XkuY/lsIpYtizA0kQdiAJwg4kQdiBJAg7kARhB5JYauutpKrN1dMRVCt10tqa8ev4YGqe\ns9G1Cgv11JxYc0x/KOzZgSQIO5AEYQeSIOxAEoQdSIKwA0ls5yque22/bPuC7fO2H2vmH7N9xfaZ\nZjrYf7kAutrOVVzXJK1FxGu2b5O0IekhSY9I+jAintz2xgpXcR3lRRaxcldq7UXLGHS+4GYfKy1c\n2LH1SzURsSlps7n9ge2LkvZ0LAXAQD7Te3bb+yTdq+m12SXpUdtnbZ+wvWvBtQFYoG2H3fatkp6X\n9HhEvC/pGUl3S9qv6Z7/qTnLHbW9bnc+Rw2ABdjWFWFs3yzpJ5J+GhFPz7h/n6SfRMSXW9bDe/YV\nw3t27Zj37Nv5NN6SnpV0cWvQmw/urntY0rmO5QFYgu0c9fankv5K0uu2zzTzvinpsO39mv4fdEnS\n13upEMBCLPXCjp44NOedOy8XK3W8aKHUMkYV6+28zRVTvEhlabmFVzI9uew6F3YEciPsQBKEHUiC\nsANJEHYgCcIOJDGas8u2dt56+ZpShSFaRz21wYo6tuVaV9vTGYG76qv129s3Qzssw54dSIKwA0kQ\ndiAJwg4kQdiBJAg7kMRoWm999ShqOke9dJ0qToRQakm5pwtjlgqqapH11RLdITq3oifzF2HPDiRB\n2IEkCDuQBGEHkiDsQBKEHUiCsANJLDXsBzamhxLOmnYUF6YxrncIUZjQC/bsQBKEHUiCsANJEHYg\nCcIOJEHYgSSWe2FH+x1Jb22ZdYekd5dWQDvqKRtbPdL4ahq6nj+MiDtn3bHUsP/Oxu31iCgcgbtc\n1FM2tnqk8dU0tnq24mU8kARhB5IYOuzHB97+jainbGz1SOOraWz1/J9B37MDWJ6h9+wAlmSQsNt+\n0Pb/2H7T9hND1HBDPZdsv277jO31gWo4Yfua7XNb5t1u+yXbbzT/7hq4nmO2rzTjdMb2wSXWs9f2\ny7Yv2D5v+7Fm/iBjVKhnsDFqs/SX8bZvkvQLSV+RdFnSq5IOR8SFpRby6ZouSZpExGD9Udt/JulD\nSf8cEV9u5v29pPci4jvNf4q7IuLvBqznmKQPI+LJZdRwQz1rktYi4jXbt0nakPSQpL/WAGNUqOcR\nDTRGbYbYs98n6c2I+FVE/EbSDyQdGqCOUYmIVyS9d8PsQ5JONrdPavrHNGQ9g4mIzYh4rbn9gaSL\nkvZooDEq1DNaQ4R9j6Rfb/n5soYfpJD0M9sbto8OXMtWuyNis7n9tqTdQxbTeNT22eZl/tLeVmxl\ne5+keyX9XCMYoxvqkUYwRrPwAd3U/RHxx5L+UtI3mpewoxLT91tDt06ekXS3pP2SNiU9tewCbN8q\n6XlJj0fE+1vvG2KMZtQz+BjNM0TYr0jau+XnLzTzBhMRV5p/r0n6saZvNcbgavPe8Pp7xGtDFhMR\nVyPi44j4RNJ3teRxsn2zpsH6fkT8qJk92BjNqmfoMSoZIuyvSrrH9hdtf17S1ySdGqAOSZLtW5oP\nWGT7FklflXSuvNTSnJJ0pLl9RNILA9ZyPUzXPawljpNtS3pW0sWIeHrLXYOM0bx6hhyjVhGx9EnS\nQU0/kf+lpG8NUcOWWv5I0n810/mh6pH0nKYv+36r6ecYfyPp9yWdlvSGpP+QdPvA9fyLpNclndU0\nZGtLrOd+TV+in5V0ppkODjVGhXoGG6O2iW/QAUnwAR2QBGEHkiDsQBKEHUiCsANJEHYgCcIOJEHY\ngST+F5N79MGV2jt3AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pa7rzkYWJ-Lq"
      },
      "source": [
        "def fonction (T,N): # We make the table evolve until the final state\n",
        "  T1= T\n",
        "  a=0\n",
        "  for i in range (10000): # the final state is reached each time well before 10000 evolutions\n",
        "    T1= evolution (T,N)\n",
        "    if (T==T1).all()== True: # we get out of the loop as soon as 2 evolutions in a row are identical (= the array will not evolve anymore)\n",
        "      a=i\n",
        "      break\n",
        "    else: \n",
        "      T=T1\n",
        "  return (T1) # we send back the final table \n",
        "\n",
        "def listeT20 (L0,N):  # we create an array list in the final state from L0\n",
        "  L20=[]\n",
        "  for k in L0:\n",
        "    L20.append(fonction(k,N))\n",
        "  return (L20)\n",
        "\n",
        "L20= listeT20 (L0, N) # L20 corresponds to the end list of L0\n",
        "\n",
        "L1,L5=shapem (L0,L20) # L1 and L5 are the compatible versions of L0 and L20 with Conv2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kIva6bV3Vril",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "22b133d9-67e2-441e-8e36-c71209475ea0"
      },
      "source": [
        "rnvideraté = Sequential() # We create our first neural network\n",
        "Depay=Conv2D(1, (3, 3), input_shape=(N, N, 1) , padding='same', activation='tanh') # a convolution with 1 filter of dimension 3.3\n",
        "rnvideraté.add(Depay)\n",
        "\n",
        "# we train our neural network with tables having undergone 1 evolution\n",
        "\n",
        "rnvideraté.compile(loss='mse', optimizer='adadelta', metrics=['accuracy'])\n",
        "rnvideraté.fit(x=L1, y=L5, batch_size=64, epochs=100, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 0s 309us/step - loss: 1.2869 - acc: 0.2594\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 0s 63us/step - loss: 1.2434 - acc: 0.2664\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 0s 57us/step - loss: 1.2001 - acc: 0.2707\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 1.1573 - acc: 0.2729\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 0s 55us/step - loss: 1.1151 - acc: 0.2756\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 1.0736 - acc: 0.2771\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 1.0330 - acc: 0.2774\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.9934 - acc: 0.2767\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.9553 - acc: 0.2749\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.9191 - acc: 0.2725\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 0s 57us/step - loss: 0.8852 - acc: 0.2706\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.8541 - acc: 0.2697\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.8261 - acc: 0.2697\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.8013 - acc: 0.2711\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.7795 - acc: 0.2745\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.7604 - acc: 0.2798\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.7438 - acc: 0.2859\n",
            "Epoch 18/100\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.7294 - acc: 0.2916\n",
            "Epoch 19/100\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.7169 - acc: 0.2995\n",
            "Epoch 20/100\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.7060 - acc: 0.3086\n",
            "Epoch 21/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.6966 - acc: 0.3184\n",
            "Epoch 22/100\n",
            "1000/1000 [==============================] - 0s 60us/step - loss: 0.6884 - acc: 0.3270\n",
            "Epoch 23/100\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.6813 - acc: 0.3358\n",
            "Epoch 24/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.6750 - acc: 0.3459\n",
            "Epoch 25/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.6695 - acc: 0.3556\n",
            "Epoch 26/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.6648 - acc: 0.3641\n",
            "Epoch 27/100\n",
            "1000/1000 [==============================] - 0s 44us/step - loss: 0.6606 - acc: 0.3729\n",
            "Epoch 28/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.6569 - acc: 0.3808\n",
            "Epoch 29/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.6536 - acc: 0.3890\n",
            "Epoch 30/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.6508 - acc: 0.3975\n",
            "Epoch 31/100\n",
            "1000/1000 [==============================] - 0s 58us/step - loss: 0.6483 - acc: 0.4054\n",
            "Epoch 32/100\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.6460 - acc: 0.4141\n",
            "Epoch 33/100\n",
            "1000/1000 [==============================] - 0s 64us/step - loss: 0.6441 - acc: 0.4219\n",
            "Epoch 34/100\n",
            "1000/1000 [==============================] - 0s 45us/step - loss: 0.6424 - acc: 0.4294\n",
            "Epoch 35/100\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.6409 - acc: 0.4370\n",
            "Epoch 36/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.6396 - acc: 0.4426\n",
            "Epoch 37/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.6385 - acc: 0.4482\n",
            "Epoch 38/100\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.6375 - acc: 0.4539\n",
            "Epoch 39/100\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.6367 - acc: 0.4562\n",
            "Epoch 40/100\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.6360 - acc: 0.4612\n",
            "Epoch 41/100\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.6354 - acc: 0.4645\n",
            "Epoch 42/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.6349 - acc: 0.4660\n",
            "Epoch 43/100\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.6345 - acc: 0.4676\n",
            "Epoch 44/100\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.6341 - acc: 0.4690\n",
            "Epoch 45/100\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.6338 - acc: 0.4698\n",
            "Epoch 46/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.6336 - acc: 0.4710\n",
            "Epoch 47/100\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.6335 - acc: 0.4718\n",
            "Epoch 48/100\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.6334 - acc: 0.4727\n",
            "Epoch 49/100\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.6333 - acc: 0.4742\n",
            "Epoch 50/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.6332 - acc: 0.4755\n",
            "Epoch 51/100\n",
            "1000/1000 [==============================] - 0s 45us/step - loss: 0.6332 - acc: 0.4777\n",
            "Epoch 52/100\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.6332 - acc: 0.4784\n",
            "Epoch 53/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.6331 - acc: 0.4787\n",
            "Epoch 54/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.6331 - acc: 0.4786\n",
            "Epoch 55/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.6331 - acc: 0.4786\n",
            "Epoch 56/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 57/100\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.6331 - acc: 0.4786\n",
            "Epoch 58/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 59/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 60/100\n",
            "1000/1000 [==============================] - 0s 65us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 61/100\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 62/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.6331 - acc: 0.4787\n",
            "Epoch 63/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 64/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 65/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.6331 - acc: 0.4787\n",
            "Epoch 66/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.6331 - acc: 0.4787\n",
            "Epoch 67/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 68/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 69/100\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.6331 - acc: 0.4787\n",
            "Epoch 70/100\n",
            "1000/1000 [==============================] - 0s 63us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 71/100\n",
            "1000/1000 [==============================] - 0s 57us/step - loss: 0.6331 - acc: 0.4787\n",
            "Epoch 72/100\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 73/100\n",
            "1000/1000 [==============================] - 0s 63us/step - loss: 0.6331 - acc: 0.4787\n",
            "Epoch 74/100\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 75/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.6331 - acc: 0.4787\n",
            "Epoch 76/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 77/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 78/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 79/100\n",
            "1000/1000 [==============================] - 0s 57us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 80/100\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 81/100\n",
            "1000/1000 [==============================] - 0s 45us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 82/100\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.6331 - acc: 0.4787\n",
            "Epoch 83/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.6331 - acc: 0.4787\n",
            "Epoch 84/100\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 85/100\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.6332 - acc: 0.4787\n",
            "Epoch 86/100\n",
            "1000/1000 [==============================] - 0s 62us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 87/100\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 88/100\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 89/100\n",
            "1000/1000 [==============================] - 0s 55us/step - loss: 0.6331 - acc: 0.4787\n",
            "Epoch 90/100\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.6331 - acc: 0.4787\n",
            "Epoch 91/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.6331 - acc: 0.4786\n",
            "Epoch 92/100\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.6331 - acc: 0.4787\n",
            "Epoch 93/100\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 94/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 95/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 96/100\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.6331 - acc: 0.4786\n",
            "Epoch 97/100\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 98/100\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.6331 - acc: 0.4788\n",
            "Epoch 99/100\n",
            "1000/1000 [==============================] - 0s 57us/step - loss: 0.6331 - acc: 0.4787\n",
            "Epoch 100/100\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.6331 - acc: 0.4788\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4159adc4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVIj9uC0EcfI",
        "outputId": "e520c7df-e45e-4907-f17a-df7ab12eb459",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "def fonction2 (T,N): # the function returns the number of changes before the table is stabilized  \n",
        "  T1= T\n",
        "  a=0\n",
        "  for i in range (1000):\n",
        "    T1= evolution (T,N)\n",
        "    if (T==T1).all()== True:\n",
        "      a=i\n",
        "      break\n",
        "    else: \n",
        "      T=T1\n",
        "  return (a) \n",
        "\n",
        "T1000= fonction2(T0,N)\n",
        "print (T1000)\n",
        "\n",
        "def listeT1000 (L0,N): # This function returns the list of the devolution number before the stabilization of the starting tables\n",
        "  L1000=[]\n",
        "  for k in L0:\n",
        "    L1000.append(fonction2(k,N))\n",
        "  return (L1000) # This list will allow us to deduce an optimal convolution number\n",
        "\n",
        "L1000=listeT1000 (L0,N)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "21\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0XcbJsHvytWI",
        "outputId": "710f9f38-787b-4fd0-8f1a-2e4ca60f4e7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "z = max(L1000)\n",
        "y= mean (L1000)\n",
        "print (z)\n",
        "print (y)\n",
        "x= int(y) # x corresponds to the average of the number of table evolutions \n",
        "print (x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36\n",
            "15.138\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDFmcvnULzHc",
        "outputId": "88440275-f0d3-41ce-d12d-4e8fe3a14980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 515
        }
      },
      "source": [
        "T20=L0[20]\n",
        "T21=L20[20]\n",
        "\n",
        "im3 = MtoIm(T20,30) # we compare a starting table and an ending table\n",
        "plt.imshow(im3)\n",
        "plt.show()\n",
        "\n",
        "im4 = MtoIm(T21,30)\n",
        "plt.imshow(im4)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nv7NO/FhW4LT2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NKN6gbX3HjwB",
        "outputId": "83d1b1bb-a9e3-41b4-cb8d-bb38f08eb082",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rnvide2= Sequential() # We create a new neural network\n",
        "rnvide2.add(Conv2D(1, (3, 3), input_shape=(N, N, 1) , padding='same', activation='tanh')) # First convolution \n",
        "for k in range (x): # We add x convolutions\n",
        "  rnvide2.add(Conv2D(1, (3, 3), padding='same', activation='tanh'))\n",
        "\n",
        "# we train the neural network with arrays in their initial and final states\n",
        "\n",
        "rnvide2.compile(loss='mse', optimizer='adadelta', metrics=['accuracy'])\n",
        "rnvide2.fit(x=L1, y=L5, batch_size=64, epochs=300, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1000/1000 [==============================] - 1s 996us/step - loss: 1.0023 - acc: 0.0042\n",
            "Epoch 2/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.9971 - acc: 0.0042\n",
            "Epoch 3/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.9954 - acc: 0.0042\n",
            "Epoch 4/300\n",
            "1000/1000 [==============================] - 0s 188us/step - loss: 0.9933 - acc: 0.0042\n",
            "Epoch 5/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.9572 - acc: 0.0161\n",
            "Epoch 6/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.5234 - acc: 0.5268\n",
            "Epoch 7/300\n",
            "1000/1000 [==============================] - 0s 169us/step - loss: 0.3417 - acc: 0.7523\n",
            "Epoch 8/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.3023 - acc: 0.7850\n",
            "Epoch 9/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.2734 - acc: 0.8009\n",
            "Epoch 10/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.2523 - acc: 0.8120\n",
            "Epoch 11/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.2409 - acc: 0.8201\n",
            "Epoch 12/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.2325 - acc: 0.8271\n",
            "Epoch 13/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.2275 - acc: 0.8420\n",
            "Epoch 14/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.2214 - acc: 0.8490\n",
            "Epoch 15/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.2171 - acc: 0.8522\n",
            "Epoch 16/300\n",
            "1000/1000 [==============================] - 0s 187us/step - loss: 0.2143 - acc: 0.8553\n",
            "Epoch 17/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.2120 - acc: 0.8570\n",
            "Epoch 18/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.2094 - acc: 0.8588\n",
            "Epoch 19/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.2077 - acc: 0.8604\n",
            "Epoch 20/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.2062 - acc: 0.8615\n",
            "Epoch 21/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.2045 - acc: 0.8627\n",
            "Epoch 22/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.2026 - acc: 0.8636\n",
            "Epoch 23/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.2013 - acc: 0.8646\n",
            "Epoch 24/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.2004 - acc: 0.8651\n",
            "Epoch 25/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1993 - acc: 0.8661\n",
            "Epoch 26/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1976 - acc: 0.8666\n",
            "Epoch 27/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.1967 - acc: 0.8670\n",
            "Epoch 28/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1957 - acc: 0.8681\n",
            "Epoch 29/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.1942 - acc: 0.8687\n",
            "Epoch 30/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1934 - acc: 0.8690\n",
            "Epoch 31/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1928 - acc: 0.8695\n",
            "Epoch 32/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1927 - acc: 0.8694\n",
            "Epoch 33/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1909 - acc: 0.8706\n",
            "Epoch 34/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.1906 - acc: 0.8708\n",
            "Epoch 35/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.1900 - acc: 0.8715\n",
            "Epoch 36/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1888 - acc: 0.8721\n",
            "Epoch 37/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.1888 - acc: 0.8727\n",
            "Epoch 38/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1876 - acc: 0.8731\n",
            "Epoch 39/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1872 - acc: 0.8732\n",
            "Epoch 40/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1869 - acc: 0.8740\n",
            "Epoch 41/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1861 - acc: 0.8740\n",
            "Epoch 42/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.1857 - acc: 0.8747\n",
            "Epoch 43/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1850 - acc: 0.8747\n",
            "Epoch 44/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1844 - acc: 0.8754\n",
            "Epoch 45/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1834 - acc: 0.8757\n",
            "Epoch 46/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.1832 - acc: 0.8760\n",
            "Epoch 47/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1829 - acc: 0.8764\n",
            "Epoch 48/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1826 - acc: 0.8765\n",
            "Epoch 49/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.1822 - acc: 0.8768\n",
            "Epoch 50/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.1816 - acc: 0.8773\n",
            "Epoch 51/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.1816 - acc: 0.8774\n",
            "Epoch 52/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.1809 - acc: 0.8779\n",
            "Epoch 53/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.1803 - acc: 0.8782\n",
            "Epoch 54/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.1804 - acc: 0.8781\n",
            "Epoch 55/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1800 - acc: 0.8785\n",
            "Epoch 56/300\n",
            "1000/1000 [==============================] - 0s 193us/step - loss: 0.1793 - acc: 0.8787\n",
            "Epoch 57/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.1788 - acc: 0.8791\n",
            "Epoch 58/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1787 - acc: 0.8794\n",
            "Epoch 59/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1783 - acc: 0.8796\n",
            "Epoch 60/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.1778 - acc: 0.8799\n",
            "Epoch 61/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.1774 - acc: 0.8802\n",
            "Epoch 62/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1772 - acc: 0.8804\n",
            "Epoch 63/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.1767 - acc: 0.8806\n",
            "Epoch 64/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.1768 - acc: 0.8809\n",
            "Epoch 65/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.1758 - acc: 0.8813\n",
            "Epoch 66/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.1757 - acc: 0.8813\n",
            "Epoch 67/300\n",
            "1000/1000 [==============================] - 0s 164us/step - loss: 0.1751 - acc: 0.8818\n",
            "Epoch 68/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1751 - acc: 0.8820\n",
            "Epoch 69/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.1749 - acc: 0.8819\n",
            "Epoch 70/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.1743 - acc: 0.8824\n",
            "Epoch 71/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1742 - acc: 0.8824\n",
            "Epoch 72/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1735 - acc: 0.8828\n",
            "Epoch 73/300\n",
            "1000/1000 [==============================] - 0s 168us/step - loss: 0.1732 - acc: 0.8831\n",
            "Epoch 74/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.1729 - acc: 0.8830\n",
            "Epoch 75/300\n",
            "1000/1000 [==============================] - 0s 168us/step - loss: 0.1727 - acc: 0.8835\n",
            "Epoch 76/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1723 - acc: 0.8838\n",
            "Epoch 77/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.1720 - acc: 0.8838\n",
            "Epoch 78/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1719 - acc: 0.8838\n",
            "Epoch 79/300\n",
            "1000/1000 [==============================] - 0s 169us/step - loss: 0.1715 - acc: 0.8844\n",
            "Epoch 80/300\n",
            "1000/1000 [==============================] - 0s 199us/step - loss: 0.1709 - acc: 0.8844\n",
            "Epoch 81/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1709 - acc: 0.8846\n",
            "Epoch 82/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1703 - acc: 0.8849\n",
            "Epoch 83/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1705 - acc: 0.8852\n",
            "Epoch 84/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1697 - acc: 0.8852\n",
            "Epoch 85/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1696 - acc: 0.8855\n",
            "Epoch 86/300\n",
            "1000/1000 [==============================] - 0s 168us/step - loss: 0.1693 - acc: 0.8857\n",
            "Epoch 87/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1687 - acc: 0.8860\n",
            "Epoch 88/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.1690 - acc: 0.8857\n",
            "Epoch 89/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.1685 - acc: 0.8863\n",
            "Epoch 90/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1679 - acc: 0.8866\n",
            "Epoch 91/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.1675 - acc: 0.8865\n",
            "Epoch 92/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.1672 - acc: 0.8866\n",
            "Epoch 93/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.1669 - acc: 0.8870\n",
            "Epoch 94/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.1666 - acc: 0.8872\n",
            "Epoch 95/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.1663 - acc: 0.8874\n",
            "Epoch 96/300\n",
            "1000/1000 [==============================] - 0s 168us/step - loss: 0.1663 - acc: 0.8874\n",
            "Epoch 97/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1656 - acc: 0.8877\n",
            "Epoch 98/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1653 - acc: 0.8878\n",
            "Epoch 99/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.1648 - acc: 0.8879\n",
            "Epoch 100/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.1645 - acc: 0.8885\n",
            "Epoch 101/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.1641 - acc: 0.8884\n",
            "Epoch 102/300\n",
            "1000/1000 [==============================] - 0s 169us/step - loss: 0.1639 - acc: 0.8885\n",
            "Epoch 103/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1636 - acc: 0.8888\n",
            "Epoch 104/300\n",
            "1000/1000 [==============================] - 0s 187us/step - loss: 0.1633 - acc: 0.8890\n",
            "Epoch 105/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.1626 - acc: 0.8895\n",
            "Epoch 106/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1620 - acc: 0.8895\n",
            "Epoch 107/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.1619 - acc: 0.8895\n",
            "Epoch 108/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.1615 - acc: 0.8901\n",
            "Epoch 109/300\n",
            "1000/1000 [==============================] - 0s 202us/step - loss: 0.1609 - acc: 0.8903\n",
            "Epoch 110/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.1603 - acc: 0.8904\n",
            "Epoch 111/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.1599 - acc: 0.8909\n",
            "Epoch 112/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.1593 - acc: 0.8912\n",
            "Epoch 113/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.1586 - acc: 0.8915\n",
            "Epoch 114/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.1577 - acc: 0.8917\n",
            "Epoch 115/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1579 - acc: 0.8920\n",
            "Epoch 116/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.1568 - acc: 0.8925\n",
            "Epoch 117/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.1560 - acc: 0.8928\n",
            "Epoch 118/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1554 - acc: 0.8934\n",
            "Epoch 119/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.1547 - acc: 0.8937\n",
            "Epoch 120/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.1544 - acc: 0.8939\n",
            "Epoch 121/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.1532 - acc: 0.8950\n",
            "Epoch 122/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.1523 - acc: 0.8952\n",
            "Epoch 123/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1517 - acc: 0.8957\n",
            "Epoch 124/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.1509 - acc: 0.8961\n",
            "Epoch 125/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1499 - acc: 0.8971\n",
            "Epoch 126/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.1491 - acc: 0.8977\n",
            "Epoch 127/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.1485 - acc: 0.8982\n",
            "Epoch 128/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1474 - acc: 0.8991\n",
            "Epoch 129/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1469 - acc: 0.8995\n",
            "Epoch 130/300\n",
            "1000/1000 [==============================] - 0s 187us/step - loss: 0.1461 - acc: 0.9005\n",
            "Epoch 131/300\n",
            "1000/1000 [==============================] - 0s 200us/step - loss: 0.1449 - acc: 0.9013\n",
            "Epoch 132/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1442 - acc: 0.9017\n",
            "Epoch 133/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1435 - acc: 0.9028\n",
            "Epoch 134/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1424 - acc: 0.9037\n",
            "Epoch 135/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1416 - acc: 0.9042\n",
            "Epoch 136/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1405 - acc: 0.9053\n",
            "Epoch 137/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1399 - acc: 0.9059\n",
            "Epoch 138/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1391 - acc: 0.9066\n",
            "Epoch 139/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1384 - acc: 0.9074\n",
            "Epoch 140/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1375 - acc: 0.9080\n",
            "Epoch 141/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1370 - acc: 0.9086\n",
            "Epoch 142/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.1362 - acc: 0.9095\n",
            "Epoch 143/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1358 - acc: 0.9098\n",
            "Epoch 144/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1349 - acc: 0.9107\n",
            "Epoch 145/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1343 - acc: 0.9111\n",
            "Epoch 146/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1335 - acc: 0.9118\n",
            "Epoch 147/300\n",
            "1000/1000 [==============================] - 0s 194us/step - loss: 0.1330 - acc: 0.9120\n",
            "Epoch 148/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1321 - acc: 0.9129\n",
            "Epoch 149/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1318 - acc: 0.9134\n",
            "Epoch 150/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1311 - acc: 0.9134\n",
            "Epoch 151/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1304 - acc: 0.9146\n",
            "Epoch 152/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.1299 - acc: 0.9145\n",
            "Epoch 153/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.1292 - acc: 0.9154\n",
            "Epoch 154/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1289 - acc: 0.9157\n",
            "Epoch 155/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1281 - acc: 0.9160\n",
            "Epoch 156/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1276 - acc: 0.9164\n",
            "Epoch 157/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.1273 - acc: 0.9167\n",
            "Epoch 158/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.1268 - acc: 0.9172\n",
            "Epoch 159/300\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.1260 - acc: 0.9176\n",
            "Epoch 160/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.1257 - acc: 0.9179\n",
            "Epoch 161/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.1250 - acc: 0.9183\n",
            "Epoch 162/300\n",
            "1000/1000 [==============================] - 0s 169us/step - loss: 0.1244 - acc: 0.9191\n",
            "Epoch 163/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1241 - acc: 0.9192\n",
            "Epoch 164/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1233 - acc: 0.9198\n",
            "Epoch 165/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1228 - acc: 0.9200\n",
            "Epoch 166/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1225 - acc: 0.9201\n",
            "Epoch 167/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.1218 - acc: 0.9209\n",
            "Epoch 168/300\n",
            "1000/1000 [==============================] - 0s 170us/step - loss: 0.1214 - acc: 0.9209\n",
            "Epoch 169/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1210 - acc: 0.9213\n",
            "Epoch 170/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.1204 - acc: 0.9219\n",
            "Epoch 171/300\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.1199 - acc: 0.9221\n",
            "Epoch 172/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.1193 - acc: 0.9227\n",
            "Epoch 173/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1189 - acc: 0.9229\n",
            "Epoch 174/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.1182 - acc: 0.9235\n",
            "Epoch 175/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1178 - acc: 0.9236\n",
            "Epoch 176/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1175 - acc: 0.9239\n",
            "Epoch 177/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1169 - acc: 0.9245\n",
            "Epoch 178/300\n",
            "1000/1000 [==============================] - 0s 169us/step - loss: 0.1161 - acc: 0.9247\n",
            "Epoch 179/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1157 - acc: 0.9250\n",
            "Epoch 180/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.1152 - acc: 0.9254\n",
            "Epoch 181/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1147 - acc: 0.9258\n",
            "Epoch 182/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.1144 - acc: 0.9261\n",
            "Epoch 183/300\n",
            "1000/1000 [==============================] - 0s 170us/step - loss: 0.1139 - acc: 0.9266\n",
            "Epoch 184/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1133 - acc: 0.9271\n",
            "Epoch 185/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1127 - acc: 0.9271\n",
            "Epoch 186/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.1123 - acc: 0.9279\n",
            "Epoch 187/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.1119 - acc: 0.9279\n",
            "Epoch 188/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1113 - acc: 0.9285\n",
            "Epoch 189/300\n",
            "1000/1000 [==============================] - 0s 169us/step - loss: 0.1111 - acc: 0.9290\n",
            "Epoch 190/300\n",
            "1000/1000 [==============================] - 0s 170us/step - loss: 0.1104 - acc: 0.9293\n",
            "Epoch 191/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.1101 - acc: 0.9297\n",
            "Epoch 192/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1094 - acc: 0.9301\n",
            "Epoch 193/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.1089 - acc: 0.9306\n",
            "Epoch 194/300\n",
            "1000/1000 [==============================] - 0s 170us/step - loss: 0.1086 - acc: 0.9311\n",
            "Epoch 195/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1079 - acc: 0.9313\n",
            "Epoch 196/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.1076 - acc: 0.9318\n",
            "Epoch 197/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.1073 - acc: 0.9323\n",
            "Epoch 198/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1067 - acc: 0.9325\n",
            "Epoch 199/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.1061 - acc: 0.9332\n",
            "Epoch 200/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.1057 - acc: 0.9336\n",
            "Epoch 201/300\n",
            "1000/1000 [==============================] - 0s 193us/step - loss: 0.1055 - acc: 0.9339\n",
            "Epoch 202/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.1048 - acc: 0.9345\n",
            "Epoch 203/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1043 - acc: 0.9346\n",
            "Epoch 204/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1038 - acc: 0.9353\n",
            "Epoch 205/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.1035 - acc: 0.9359\n",
            "Epoch 206/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.1030 - acc: 0.9361\n",
            "Epoch 207/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.1027 - acc: 0.9365\n",
            "Epoch 208/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1021 - acc: 0.9371\n",
            "Epoch 209/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.1018 - acc: 0.9374\n",
            "Epoch 210/300\n",
            "1000/1000 [==============================] - 0s 194us/step - loss: 0.1013 - acc: 0.9383\n",
            "Epoch 211/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.1009 - acc: 0.9382\n",
            "Epoch 212/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1005 - acc: 0.9390\n",
            "Epoch 213/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.1002 - acc: 0.9390\n",
            "Epoch 214/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.0997 - acc: 0.9397\n",
            "Epoch 215/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.0994 - acc: 0.9400\n",
            "Epoch 216/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.0989 - acc: 0.9406\n",
            "Epoch 217/300\n",
            "1000/1000 [==============================] - 0s 187us/step - loss: 0.0987 - acc: 0.9408\n",
            "Epoch 218/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.0982 - acc: 0.9412\n",
            "Epoch 219/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.0978 - acc: 0.9415\n",
            "Epoch 220/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.0975 - acc: 0.9419\n",
            "Epoch 221/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.0971 - acc: 0.9425\n",
            "Epoch 222/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.0967 - acc: 0.9424\n",
            "Epoch 223/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.0964 - acc: 0.9431\n",
            "Epoch 224/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.0962 - acc: 0.9433\n",
            "Epoch 225/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.0959 - acc: 0.9435\n",
            "Epoch 226/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.0955 - acc: 0.9437\n",
            "Epoch 227/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.0951 - acc: 0.9440\n",
            "Epoch 228/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.0948 - acc: 0.9441\n",
            "Epoch 229/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.0946 - acc: 0.9447\n",
            "Epoch 230/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.0944 - acc: 0.9449\n",
            "Epoch 231/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.0941 - acc: 0.9451\n",
            "Epoch 232/300\n",
            "1000/1000 [==============================] - 0s 170us/step - loss: 0.0940 - acc: 0.9450\n",
            "Epoch 233/300\n",
            "1000/1000 [==============================] - 0s 193us/step - loss: 0.0936 - acc: 0.9458\n",
            "Epoch 234/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.0933 - acc: 0.9455\n",
            "Epoch 235/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.0931 - acc: 0.9462\n",
            "Epoch 236/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.0930 - acc: 0.9461\n",
            "Epoch 237/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.0925 - acc: 0.9465\n",
            "Epoch 238/300\n",
            "1000/1000 [==============================] - 0s 170us/step - loss: 0.0922 - acc: 0.9468\n",
            "Epoch 239/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.0921 - acc: 0.9469\n",
            "Epoch 240/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.0919 - acc: 0.9471\n",
            "Epoch 241/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.0918 - acc: 0.9469\n",
            "Epoch 242/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.0914 - acc: 0.9474\n",
            "Epoch 243/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.0912 - acc: 0.9476\n",
            "Epoch 244/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.0909 - acc: 0.9479\n",
            "Epoch 245/300\n",
            "1000/1000 [==============================] - 0s 166us/step - loss: 0.0909 - acc: 0.9481\n",
            "Epoch 246/300\n",
            "1000/1000 [==============================] - 0s 167us/step - loss: 0.0905 - acc: 0.9482\n",
            "Epoch 247/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.0904 - acc: 0.9483\n",
            "Epoch 248/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.0902 - acc: 0.9486\n",
            "Epoch 249/300\n",
            "1000/1000 [==============================] - 0s 168us/step - loss: 0.0899 - acc: 0.9489\n",
            "Epoch 250/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.0897 - acc: 0.9488\n",
            "Epoch 251/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.0897 - acc: 0.9494\n",
            "Epoch 252/300\n",
            "1000/1000 [==============================] - 0s 187us/step - loss: 0.0894 - acc: 0.9494\n",
            "Epoch 253/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.0891 - acc: 0.9494\n",
            "Epoch 254/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.0892 - acc: 0.9496\n",
            "Epoch 255/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.0889 - acc: 0.9497\n",
            "Epoch 256/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.0888 - acc: 0.9499\n",
            "Epoch 257/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.0884 - acc: 0.9500\n",
            "Epoch 258/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.0882 - acc: 0.9506\n",
            "Epoch 259/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.0881 - acc: 0.9505\n",
            "Epoch 260/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.0879 - acc: 0.9504\n",
            "Epoch 261/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.0877 - acc: 0.9509\n",
            "Epoch 262/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.0875 - acc: 0.9510\n",
            "Epoch 263/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.0873 - acc: 0.9510\n",
            "Epoch 264/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.0871 - acc: 0.9515\n",
            "Epoch 265/300\n",
            "1000/1000 [==============================] - 0s 170us/step - loss: 0.0872 - acc: 0.9511\n",
            "Epoch 266/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.0869 - acc: 0.9518\n",
            "Epoch 267/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.0867 - acc: 0.9514\n",
            "Epoch 268/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.0866 - acc: 0.9518\n",
            "Epoch 269/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.0866 - acc: 0.9516\n",
            "Epoch 270/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.0862 - acc: 0.9524\n",
            "Epoch 271/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.0862 - acc: 0.9522\n",
            "Epoch 272/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.0860 - acc: 0.9524\n",
            "Epoch 273/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.0859 - acc: 0.9520\n",
            "Epoch 274/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.0856 - acc: 0.9527\n",
            "Epoch 275/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.0856 - acc: 0.9526\n",
            "Epoch 276/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.0855 - acc: 0.9526\n",
            "Epoch 277/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.0851 - acc: 0.9529\n",
            "Epoch 278/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.0850 - acc: 0.9532\n",
            "Epoch 279/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.0849 - acc: 0.9532\n",
            "Epoch 280/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.0847 - acc: 0.9531\n",
            "Epoch 281/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.0845 - acc: 0.9535\n",
            "Epoch 282/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.0844 - acc: 0.9535\n",
            "Epoch 283/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.0842 - acc: 0.9539\n",
            "Epoch 284/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.0841 - acc: 0.9538\n",
            "Epoch 285/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.0841 - acc: 0.9539\n",
            "Epoch 286/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.0838 - acc: 0.9543\n",
            "Epoch 287/300\n",
            "1000/1000 [==============================] - 0s 167us/step - loss: 0.0837 - acc: 0.9542\n",
            "Epoch 288/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.0833 - acc: 0.9543\n",
            "Epoch 289/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.0832 - acc: 0.9549\n",
            "Epoch 290/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.0831 - acc: 0.9546\n",
            "Epoch 291/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.0831 - acc: 0.9548\n",
            "Epoch 292/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.0829 - acc: 0.9549\n",
            "Epoch 293/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.0828 - acc: 0.9549\n",
            "Epoch 294/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.0825 - acc: 0.9552\n",
            "Epoch 295/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.0825 - acc: 0.9554\n",
            "Epoch 296/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.0824 - acc: 0.9554\n",
            "Epoch 297/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.0821 - acc: 0.9558\n",
            "Epoch 298/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.0820 - acc: 0.9555\n",
            "Epoch 299/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.0821 - acc: 0.9556\n",
            "Epoch 300/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.0817 - acc: 0.9560\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f41599f8400>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blkfziTr0Xxu",
        "outputId": "e439f3c1-b578-4adb-a7c6-05f7cb0c2805",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 533
        }
      },
      "source": [
        "H2=rnvide2.predict(L1, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
        "\n",
        "H3=np.around(H2) # H3 correspond à la prédiction de L1\n",
        "\n",
        "# we test the neural network by visually comparing the prediction and the real final state\n",
        "\n",
        "t=rd.randint (0,1001)\n",
        "print(t)\n",
        "im34 = MtoIm(L5[t],30) # we visually compare the arrival list and the prediction according to the neural network\n",
        "plt.imshow(im34) \n",
        "plt.show()\n",
        "\n",
        "im35 = MtoIm(H3[t],30)\n",
        "plt.imshow(im35)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "670\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nBGEHkiDsQBKEHUiCsANJ/BeC+unbV18LLAAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIOxAEoQdSIKwA0n8F59QBezVqinMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4VVKny1N8CR",
        "outputId": "e29d845a-ac42-428f-c3b3-0cb05eb73628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def evolution2 (T,N): # we rewrite the evolution with the new rules\n",
        "  M=np.zeros ((N,N))\n",
        "  a=0\n",
        "  b=0\n",
        "  for i in range (N):\n",
        "    for j in range (N):\n",
        "      if i>0 and i<N-1 and j>0 and j<N-1:\n",
        "        a=T[i,j]+T[i+1,j]+T[i-1,j]+T[i,j+1]+T[i,j-1]+T[i+1,j+1]+T[i+1,j-1]+T[i-1,j+1]+T[i-1,j-1]\n",
        "      if i==0 and j!=0 and j!=N-1:\n",
        "        a=T[i,j]+T[i+1,j]+T[i,j+1]+T[i,j-1]+T[i+1,j+1]+T[i+1,j-1]\n",
        "      if i==N-1 and j!=0 and j!=N-1:\n",
        "        a=T[i,j]+T[i-1,j]+T[i,j+1]+T[i,j-1]+T[i-1,j+1]+T[i-1,j-1]\n",
        "      if j==0 and i!=0 and i!=N-1:\n",
        "        a=T[i,j]+T[i+1,j]+T[i-1,j]+T[i,j+1]+T[i+1,j+1]+T[i-1,j+1]\n",
        "      if j==N-1 and i!=0 and i!=N-1:\n",
        "        a=T[i,j]+T[i+1,j]+T[i-1,j]+T[i,j-1]+T[i+1,j-1]+T[i-1,j-1]\n",
        "      if i==0 and j==0:\n",
        "        a=T[i,j]+T[i+1,j]+T[i,j+1]+T[i+1,j+1]\n",
        "      if i==0 and j==N-1:\n",
        "        a=T[i,j]+T[i+1,j]+T[i,j-1]+T[i+1,j-1]\n",
        "      if i==N-1 and j==0:\n",
        "        a=T[i,j]+T[i-1,j]+T[i,j+1]+T[i-1,j+1]\n",
        "      if i==N-1 and j==N-1:\n",
        "        a=T[i,j]+T[i-1,j]+T[i,j-1]+T[i-1,j-1]\n",
        "      if a==0:\n",
        "        b=0\n",
        "      elif a<0 and T[i,j]!=1: # we have to change some conditions\n",
        "        b=-1\n",
        "      elif a<0 and T[i,j]==1: # we forbid the transformation from 1 to -1\n",
        "        b=0\n",
        "      elif a>0 and T[i,j]!=-1:\n",
        "        b=1\n",
        "      elif a>0 and T[i,j]==-1:# # we forbid the transformation from -1 to 1\n",
        "        b=0\n",
        "      M[i,j]=b\n",
        "  return (M)\n",
        "\n",
        "M16= evolution2 (T0,30)\n",
        "print (T0)\n",
        "print (M16)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[-1.  0.  0. -1.  1. -1.  1.  1.  1.  1.  0.  1.  0.  0. -1.  0.  1. -1.\n",
            "   1. -1.  0.  1.  0.  1.  0. -1.  1.  0.  0. -1.]\n",
            " [-1.  1. -1.  0.  0.  0.  0.  0.  1.  0.  0. -1. -1.  0.  1.  1. -1.  1.\n",
            "  -1.  1.  1.  1.  0.  1. -1.  1.  0.  1.  0.  1.]\n",
            " [ 1.  1.  1.  0. -1.  1.  1.  0.  0.  0.  0. -1.  1. -1.  0.  0.  0.  0.\n",
            "  -1. -1. -1.  1.  1.  0.  1.  0.  1. -1.  1. -1.]\n",
            " [-1. -1.  1. -1. -1.  0. -1. -1.  1.  0. -1. -1. -1.  1. -1.  0. -1.  0.\n",
            "   0. -1. -1.  0.  0.  0.  1. -1.  0.  1. -1.  1.]\n",
            " [ 0. -1.  0.  1.  0.  1. -1. -1.  1.  0. -1.  0.  1. -1.  0. -1. -1.  1.\n",
            "   0. -1.  0. -1. -1.  1.  1. -1. -1. -1. -1. -1.]\n",
            " [ 0.  1. -1.  0.  1.  0.  1.  0.  1. -1.  0.  1. -1.  0. -1. -1.  0. -1.\n",
            "   1.  0.  1. -1.  0.  1. -1.  1.  1.  1. -1. -1.]\n",
            " [ 1. -1.  0.  0.  0. -1.  0.  0.  1.  1.  1. -1.  0.  0.  0.  1.  1.  0.\n",
            "   1. -1.  1.  0.  0. -1. -1.  0.  1.  1. -1.  1.]\n",
            " [ 0.  1. -1.  1.  1.  0.  0. -1.  0.  1.  1.  0.  1. -1.  1.  0.  0.  0.\n",
            "  -1.  0.  0.  0.  0.  0. -1.  1. -1.  0.  0. -1.]\n",
            " [ 0. -1.  0.  0.  0.  1. -1.  1.  1.  0. -1.  1.  0.  1.  0.  0.  0. -1.\n",
            "   0.  1. -1. -1.  0.  0.  1.  1. -1.  0.  1. -1.]\n",
            " [-1.  1.  1.  1.  1. -1.  1. -1.  0.  1.  1.  1.  1.  0.  1.  1.  1.  0.\n",
            "   0. -1.  0. -1.  1.  0. -1. -1.  1.  0.  0.  0.]\n",
            " [ 0. -1.  0. -1.  1.  0. -1.  0. -1. -1.  0.  1.  0.  0. -1.  0.  1.  1.\n",
            "  -1.  0. -1.  0.  0. -1. -1.  1.  1.  0.  1.  0.]\n",
            " [-1.  0.  1.  1. -1. -1.  0.  1.  1.  1.  0.  1. -1.  1.  0.  1. -1.  0.\n",
            "   0.  1.  0.  0.  0. -1.  0.  0.  1. -1. -1. -1.]\n",
            " [ 0.  1.  1.  0. -1.  1. -1.  0.  1.  0.  0.  0.  0. -1.  0.  1.  0.  0.\n",
            "   1.  0. -1.  1.  1.  0. -1.  0.  1. -1. -1.  1.]\n",
            " [ 0.  1.  0. -1.  1.  1.  1. -1.  0.  1.  0. -1. -1. -1.  1. -1. -1.  1.\n",
            "   0.  0.  1.  0.  0.  0. -1.  1.  1. -1.  0.  0.]\n",
            " [ 1.  0.  1.  0.  0.  1.  0.  0. -1.  0.  1. -1.  0.  1.  0.  0.  1. -1.\n",
            "   1. -1. -1.  0. -1.  0. -1.  0.  1.  0.  1.  1.]\n",
            " [ 0.  1.  1.  0. -1.  0. -1.  1. -1. -1.  1.  0.  0. -1.  0.  0.  0.  0.\n",
            "   0.  0.  1.  1. -1. -1.  0.  0.  1.  0. -1.  1.]\n",
            " [ 1. -1.  0. -1. -1.  1. -1. -1. -1. -1.  0.  0. -1.  0. -1. -1. -1.  1.\n",
            "   0.  0.  1.  0.  1.  1. -1. -1.  1. -1. -1.  0.]\n",
            " [ 1.  0.  0.  1.  1.  1.  0. -1.  0.  1.  1. -1.  1. -1.  0. -1.  0.  0.\n",
            "  -1.  1. -1.  0. -1. -1.  0. -1.  1.  0. -1. -1.]\n",
            " [-1.  1.  0.  0.  0.  1.  1.  1. -1. -1.  1.  0. -1.  0.  0.  0.  1.  0.\n",
            "   1.  1.  0.  0.  0.  0.  0.  1. -1.  1.  1.  0.]\n",
            " [ 1.  0.  0.  0. -1.  1.  0.  0.  1. -1.  1. -1. -1.  1.  1.  0.  0.  0.\n",
            "   1.  0.  1.  1. -1.  0. -1.  1.  1. -1.  0.  0.]\n",
            " [ 0.  0. -1.  1.  0. -1. -1. -1.  0.  0. -1.  0. -1.  0. -1.  1.  0.  1.\n",
            "  -1.  0. -1.  1. -1. -1. -1.  0. -1.  0.  0.  0.]\n",
            " [-1.  0. -1.  0.  0.  1.  0.  0.  0.  0.  0.  1.  1.  0.  0. -1.  0. -1.\n",
            "   0.  0.  1.  0.  1.  1. -1. -1.  1.  0.  1.  0.]\n",
            " [-1. -1. -1. -1. -1.  0.  0.  1. -1.  0. -1. -1.  1.  1.  1. -1.  0.  0.\n",
            "   1. -1. -1.  0. -1.  1.  1. -1.  0.  0.  0.  1.]\n",
            " [ 1.  0.  1.  0.  1. -1. -1.  1.  0.  1.  0. -1.  1.  1. -1.  1.  1.  0.\n",
            "  -1.  1. -1.  1.  1. -1.  1. -1.  0. -1. -1. -1.]\n",
            " [ 0.  0. -1.  0.  1.  1.  0.  1. -1. -1.  0. -1.  1. -1.  1. -1.  1. -1.\n",
            "   1.  0. -1.  0. -1. -1. -1. -1. -1.  1.  1.  0.]\n",
            " [ 0.  1. -1.  1. -1. -1. -1.  0.  1.  0.  1.  1.  0.  1. -1.  0.  0.  0.\n",
            "   0. -1. -1.  1. -1.  0.  0. -1.  0.  1.  1.  0.]\n",
            " [ 1.  0.  1.  1.  0.  1. -1.  1.  1.  1.  1.  0. -1.  1.  1.  0.  1.  1.\n",
            "   0.  0.  0. -1.  1. -1. -1. -1.  1. -1.  1.  0.]\n",
            " [ 0. -1. -1.  1.  0.  1.  1.  1. -1. -1. -1.  0.  0.  1. -1.  1. -1.  1.\n",
            "  -1.  0. -1. -1.  1. -1. -1.  0. -1.  0.  0. -1.]\n",
            " [ 1.  1.  1.  1.  1.  0.  0.  0.  1.  0. -1.  0. -1. -1.  0.  0. -1. -1.\n",
            "  -1.  0. -1.  1. -1.  1. -1.  0.  0.  0. -1.  0.]\n",
            " [ 0. -1. -1.  0. -1.  0.  1. -1. -1.  0.  1.  0. -1.  1. -1.  0.  1.  1.\n",
            "   0. -1.  0.  1.  0.  1.  1.  0. -1. -1.  0.  0.]]\n",
            "[[-1. -1. -1. -1.  0.  0.  1.  1.  1.  1.  1.  0. -1. -1.  0.  1.  1.  0.\n",
            "   0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.  0.]\n",
            " [ 0.  1.  0. -1. -1.  1.  1.  1.  1.  1.  0. -1. -1. -1.  0.  1.  0.  0.\n",
            "  -1.  0.  1.  1.  1.  1.  0.  1.  1.  1.  0.  0.]\n",
            " [ 0.  1.  1. -1. -1.  0.  0.  1.  1.  1. -1. -1.  0. -1.  1. -1.  0. -1.\n",
            "  -1. -1.  0.  1.  1.  1.  1.  1.  1.  0.  1.  0.]\n",
            " [-1.  0.  1.  0.  0. -1. -1. -1.  0.  0. -1. -1. -1.  0. -1. -1. -1. -1.\n",
            "  -1. -1. -1. -1.  1.  1.  1.  0. -1.  0. -1.  0.]\n",
            " [-1. -1. -1.  0.  1.  0. -1.  0.  0.  0. -1. -1.  0. -1. -1. -1. -1.  0.\n",
            "  -1. -1. -1. -1. -1.  1.  1.  0.  0. -1. -1. -1.]\n",
            " [ 0.  0. -1.  1.  1.  1.  0.  1.  1.  0.  0.  0. -1. -1. -1. -1. -1.  0.\n",
            "   0.  1.  0. -1. -1.  0.  0.  0.  1.  0. -1. -1.]\n",
            " [ 1.  0.  0.  1.  1.  0. -1.  1.  1.  1.  1.  0. -1. -1. -1.  1.  0.  1.\n",
            "   0.  0.  0.  1. -1. -1. -1.  0.  1.  1. -1.  0.]\n",
            " [ 0.  0. -1.  1.  1.  0. -1.  0.  1.  1.  1.  1.  1.  0.  1.  1.  1.  0.\n",
            "  -1.  0. -1. -1. -1. -1.  0.  0.  0.  0.  0. -1.]\n",
            " [ 0.  0.  1.  1.  1.  1. -1.  0.  1.  1.  0.  1.  1.  1.  1.  1.  1. -1.\n",
            "  -1.  0. -1. -1. -1.  0.  0.  0.  0.  0.  0. -1.]\n",
            " [-1.  0.  0.  1.  1.  0.  0. -1.  0.  0.  1.  1.  1.  1.  1.  1.  1.  1.\n",
            "  -1. -1. -1. -1.  0. -1. -1.  0.  1.  1.  1.  1.]\n",
            " [-1.  0.  1.  0.  0. -1. -1.  0.  0.  0.  1.  1.  1.  1.  0.  1.  1.  1.\n",
            "   0. -1. -1. -1. -1. -1. -1.  1.  1.  1.  0. -1.]\n",
            " [-1.  1.  1.  1. -1. -1. -1.  0.  1.  1.  1.  1.  0.  0.  1.  1.  0.  1.\n",
            "   1.  0.  0.  0.  0. -1. -1.  1.  1.  0. -1. -1.]\n",
            " [ 1.  1.  1.  1.  0.  0.  0.  1.  1.  1.  1. -1. -1. -1.  1.  0.  0.  0.\n",
            "   1.  1.  0.  1.  1. -1. -1.  1.  1. -1. -1.  0.]\n",
            " [ 1.  1.  1.  0.  1.  1.  1. -1.  0.  1.  0. -1. -1. -1.  0.  0.  0.  1.\n",
            "   1.  0.  0.  0.  1. -1. -1.  1.  1.  0.  0.  1.]\n",
            " [ 1.  1.  1.  1.  1.  1.  1. -1. -1.  0.  0. -1. -1.  0. -1.  0.  0.  0.\n",
            "   0.  0.  0.  0. -1. -1. -1.  1.  1.  1.  1.  1.]\n",
            " [ 1.  1.  1. -1. -1. -1.  0.  0. -1. -1.  0.  0. -1. -1. -1. -1. -1.  1.\n",
            "   0.  1.  1.  1.  0. -1. -1.  0.  1.  1.  0.  1.]\n",
            " [ 1.  0.  1.  0.  0.  0. -1. -1. -1. -1.  0.  1. -1. -1. -1. -1. -1.  0.\n",
            "   1.  1.  1.  1.  0.  0. -1.  0.  0. -1. -1. -1.]\n",
            " [ 1.  1.  0.  0.  1.  1.  1. -1. -1.  0.  0.  0.  0. -1. -1. -1. -1.  1.\n",
            "   0.  1.  0.  0.  0. -1. -1. -1.  0.  0. -1. -1.]\n",
            " [ 0.  1.  1.  1.  1.  1.  1.  1. -1.  0.  0.  0. -1.  0.  0.  1.  0.  1.\n",
            "   1.  1.  1. -1. -1. -1. -1.  1.  0.  1.  0. -1.]\n",
            " [ 1.  0.  1. -1.  0.  0.  1.  0.  0. -1.  0. -1. -1.  0.  1.  1.  1.  1.\n",
            "   1.  1.  1.  0. -1. -1. -1.  0.  1.  0.  1.  1.]\n",
            " [ 0. -1. -1.  0.  1. -1. -1. -1. -1.  0. -1. -1.  0.  0.  0.  0.  0.  0.\n",
            "   0.  1.  0.  1.  0. -1. -1. -1.  0.  1.  0.  1.]\n",
            " [-1. -1. -1. -1. -1.  0. -1. -1. -1. -1. -1.  0.  1.  1.  0. -1. -1.  0.\n",
            "  -1. -1.  0. -1.  1.  0. -1. -1.  0.  1.  1.  1.]\n",
            " [-1. -1. -1. -1. -1. -1.  1.  0.  0. -1. -1.  0.  1.  1.  1.  0. -1.  0.\n",
            "   0. -1.  0.  1.  0.  1.  0. -1. -1.  0. -1.  0.]\n",
            " [ 0. -1.  0. -1.  0.  0.  0.  0.  1.  0. -1. -1.  1.  1.  0.  1.  0.  1.\n",
            "   0.  0. -1.  0.  0. -1.  0. -1. -1. -1.  0.  0.]\n",
            " [ 1.  1.  0.  1.  1.  0. -1.  0.  0.  0.  0.  0.  1.  0.  0.  0.  1.  0.\n",
            "   0. -1. -1. -1. -1. -1. -1. -1. -1.  1.  1.  0.]\n",
            " [ 1.  1.  0.  1.  0. -1.  0.  1.  1.  1.  1.  1.  1.  1.  0.  1.  1.  1.\n",
            "   0. -1. -1.  0. -1. -1. -1. -1. -1.  1.  1.  1.]\n",
            " [ 1.  0.  1.  1.  1.  0.  0.  1.  1.  1.  1.  1.  0.  1.  1.  0.  1.  1.\n",
            "   0. -1. -1. -1.  0. -1. -1. -1.  0.  0.  1.  1.]\n",
            " [ 1.  0.  0.  1.  1.  1.  1.  1.  0.  0. -1. -1. -1.  0.  0.  0.  0.  0.\n",
            "  -1. -1. -1. -1.  0. -1. -1. -1. -1. -1. -1. -1.]\n",
            " [ 0.  0.  0.  1.  1.  1.  1.  1.  0. -1. -1. -1. -1. -1.  0. -1.  0. -1.\n",
            "  -1. -1. -1.  0.  0.  0.  0. -1. -1. -1. -1. -1.]\n",
            " [ 1.  0.  0.  1.  0.  1.  0.  0. -1.  0.  0. -1. -1.  0. -1. -1.  0.  0.\n",
            "  -1. -1.  0.  0.  1.  1.  1. -1. -1. -1. -1. -1.]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9rMLHFXIQXHn",
        "outputId": "5ac30c8c-a318-419b-b423-b03239e445ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 764
        }
      },
      "source": [
        "im = MtoIm(T0,30) # we visually compare the differences between the two rules\n",
        "plt.imshow(im)\n",
        "plt.show()\n",
        "\n",
        "im11 = MtoIm(M0,30)\n",
        "plt.imshow(im11)\n",
        "plt.show()\n",
        "\n",
        "im16 = MtoIm(M16,30)\n",
        "plt.imshow(im16)\n",
        "plt.show()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAO20lEQVR4nO3dT6hc53nH8d+vjrOxvZBrVQhFVKnx\nJgQqVxdTiCkuJcHVxvbGxIuggkFZxGBDFjXpIlqaYjt0ZVBqEbWkDgEn2ITQRBUG043xyKiy/rSx\nY2QiIUsyXthepXaeLu5RuFHvvOf6PfPOOaPn+4FBc2funPPMO/enc2aeec9xRAjAje+Pxi4AwHIQ\ndiAJwg4kQdiBJAg7kARhB5L43JAH275f0j9JuknSP0fEU8Xfv8OhPXPuPFFe176K+vr0rLKsVFBp\nwS2eSEP7Cs+ld/ym9lxHeF2qx6+2nvNSvB/e7C7X9tlt3yTpV5K+KumCpNclPRIRZ+c+Zs2h2bw7\ny+tr8W2AnlWWlQoqLXjFvtaw+Z/Nut7xm9pzHeF1qR6/2nrWpJhtvtYhu/H3SHo7It6JiN9K+pGk\nBwYsD0BDQ8K+S9JvNvx8obsNwAQ1/4DO9kHbM9szXW29NgDzDAn7RUm7N/z8he62PxARhyNiLSLW\ntH3A2gAMMiTsr0u6y/YXbX9e0tclvbyYsgAsWnXrLSI+sf2YpF9ovfV2JCLOLKwyLE9lW6LvA+NB\n3Y7ahU6tA1BQLLXnedaMbXXrrQatt57HjaVQ75ByPcaLNrHXpdR6G6L4VGLxrTcAK4SwA0kQdiAJ\nwg4kQdiBJAg7kMSgKa6f1b4T0qyyFVHbwSh1VAZ1W2pnM02wTzxGt2rps8GGPHaEtnCfeetcKzyG\nLTuQBGEHkiDsQBKEHUiCsANJEHYgiaW23kqGHLyw2cyiynU2a+mN0iOrXOdW7q9ZJ6qxZQeSIOxA\nEoQdSIKwA0kQdiAJwg4kMZnWW1+7pVV7rWiMdRYUZ4oNaFfVPnbQOic2thmwZQeSIOxAEoQdSIKw\nA0kQdiAJwg4kMaj1Zvu8pI8kfSrpk4goHe9OJzS5blbZkBlfDazU2PVpdPDHJjPmepZZPbmv9qCb\nqnuai+iz/3VEvL+A5QBoiN14IImhYQ9Jv7R9wvbBRRQEoI2hu/H3RsRF238i6Zjt/46IVzf+Qvef\nAP8RACNzxGI+0bB9SNLHEfF04Xfmr2yC342vPSxVK83OlLJKJnhGnVotPqBbkzSLzZdcvRtv+xbb\nt127Lulrkk7XLg9AW0N243dI+qnXpy99TtK/RcS/L6QqAAtXHfaIeEfSny+wlsm5YXbVh+z6DhiD\nMfaom0yd7XsilUf2HTJFuOZ1ofUGJEHYgSQIO5AEYQeSIOxAEoQdSGK5R5fdJ2m21DU20+o8irUP\nHtImLLWrJjbLt1eLdt8Uj4RbUxJbdiAJwg4kQdiBJAg7kARhB5Ig7EAS0zmxY49mra5apdlMQ1o1\nlW2wQSr7a1M8TkRxJlnlc1ny5LRm2LIDSRB2IAnCDiRB2IEkCDuQBGEHkliZ1ttKTb8a0KsZ4yCX\nQ45f3sKQVtfUzi9Qv9DFL5ItO5AEYQeSIOxAEoQdSIKwA0kQdiAJwg4k0Rt220dsX7F9esNtt9s+\nZvut7t9tbcvsqbFwWTWOuksrMcKl9HoOuayS2rHbV1jmVrbsP5B0/3W3PSnpeETcJel49zOACesN\ne0S8KumD625+QNLR7vpRSQ8uuC4AC1b7nn1HRFzqrr8nace8X7R90PbM9kxXK9cGYLDBH9BFxLW3\nC/PuPxwRaxGxpu1D1wagVm3YL9veKUndv1cWVxKAFmrD/rKkA931A5JeWkw5AFrpneJq+wVJ90m6\nw/YFSd+V9JSkH9t+VNK7kh5uWWQmxemmlS22vrZT9ezhnnqqp85ObIpw7yIbHPp4yGs2T2/YI+KR\nOXf9TcX6AIyEb9ABSRB2IAnCDiRB2IEkCDuQxOocXXZqJxisrKfV7KtWJ74sPpchT6a2qAHrbDU7\nsLrFuOSpeGzZgSQIO5AEYQeSIOxAEoQdSIKwA0msTuutQT9r0MyiRv21MQ6MWL3OnlbW1A7yWDsj\nrq9l16Kl16JLyJYdSIKwA0kQdiAJwg4kQdiBJAg7kARhB5JYnT57QXWfc0AjuPoopqPMxy2rLqln\nDFqecHKZWhyxdqiaktiyA0kQdiAJwg4kQdiBJAg7kARhB5LoDbvtI7av2D694bZDti/aPtld9rct\ns5HouVRy4dJM4Xm471KqufC4Xi0Gouc1G1TvktWOu0tjsG/++rayZf+BpPs3uf17EbG3u/x8q08Q\nwDh6wx4Rr0r6YAm1AGhoyHv2x2yf6nbzty2sIgBN1Ib9OUl3Stor6ZKkZ+b9ou2Dtme2Z7pauTYA\ng1WFPSIuR8SnEfE7Sd+XdE/hdw9HxFpErGl7bZkAhqoKu+2dG358SNLpeb8LYBp6Z73ZfkHSfZLu\nsH1B0ncl3Wd7r9Y/7D8v6ZtbWtsJzW279HVGmrROWvXCJtjmGQXjMCmOWN4rYs+P7BTDXj1zdtX+\nyCtPAds39XNq4zC1qarFcmrHbk2K2ebPlG/QAUkQdiAJwg4kQdiBJAg7kARhB5JY6tFl90ma1T64\nsj00hlKLZ2rtKEnV4zfJ59JAb8eu8oy+jU4EPBdbdiAJwg4kQdiBJAg7kARhB5Ig7EASK3Nix9o2\nxdRmOg2pp7b72Nsia9XWHKNdOsLr3eJvrHdGYcUy2bIDSRB2IAnCDiRB2IEkCDuQBGEHkliZ1lvt\nDKvS46bWluvTbJJZ5YJbtREHKTyX4jpX7G+hBlt2IAnCDiRB2IEkCDuQBGEHkiDsQBK9Ybe92/Yr\nts/aPmP78e72220fs/1W9++2ppW6cCkIz78MKifaXKrXWTc845lYwTHgUmvQEMwrZt/8h2xly/6J\npG9HxJck/aWkb9n+kqQnJR2PiLskHe9+BjBRvWGPiEsR8UZ3/SNJ5yTtkvSApKPdrx2V9GCrIgEM\n95nes9veI+luSa9J2hERl7q73pO0Y6GVAVioLYfd9q2SXpT0RER8uPG+WD/J+6ZvX2wftD2zPbs6\nqFQAQ2wp7LZv1nrQfxgRP+luvmx7Z3f/TklXNntsRByOiLWIWNu+iIoBVNnKp/GW9LykcxHx7Ia7\nXpZ0oLt+QNJLiy8PwKJsZdbbVyR9Q9Kbtk92t31H0lOSfmz7UUnvSnq4TYkAFsHrb7eXtDIXOslD\njoBaqdWBU4csuHhSyMpVDjoBY+WJCYcY44SRzabr1j6XvnrmLXdNitnmz4Zv0AFJEHYgCcIOJEHY\ngSQIO5AEYQeSWJmjy47QjSkq1lPZPmtl1Y6iO8YJIVsNUaux58SOAOYi7EAShB1IgrADSRB2IAnC\nDiSx3NbbPkmzpa5x0IykFm2TIZ2jqbUfbySrNrbz/jbXCo9hyw4kQdiBJAg7kARhB5Ig7EAShB1I\nYjqz3hrNDioeiLHnsSNMvlq5gy020Wxwq+4adCzUKbX02LIDSRB2IAnCDiRB2IEkCDuQBGEHktjK\nWVx3237F9lnbZ2w/3t1+yPZF2ye7y/725QKotZU++yeSvh0Rb9i+TdIJ28e6+74XEU8vopAp9SN/\nr1BUsTW9Ko3XTrG3P+C51J6kstX4tTrHYvXfSWmRDb770Bv2iLgk6VJ3/SPb5yTtWnwpAFr6TO/Z\nbe+RdLek17qbHrN9yvYR29sWXBuABdpy2G3fKulFSU9ExIeSnpN0p6S9Wt/yPzPncQdtz2zPdHUB\nFQOo4oj+dzK2b5b0M0m/iIhnN7l/j6SfRcSXi8tZc8w7LNUY389u9j30FXvPXjTGe/biQmsfWP83\nNuQ9e63aWtckzWLzR2/l03hLel7SuY1Bt71zw689JOl0XXkAlmErn8Z/RdI3JL1p+2R323ckPWJ7\nr9b/Xzsv6ZtNKgSwEFv5NP4/tfmezM8XWcigXerCLk9psX27StVHpr2RdtUbLbZZG6z02MJKS38L\nQ6a41qrOQ+HwsnyDDkiCsANJEHYgCcIOJEHYgSQIO5DEdI4uO8SQQ8guf7FL1+rbie5Z7hgdyDG+\niVn9TcElDxBbdiAJwg4kQdiBJAg7kARhB5Ig7EASN0brraDZbLpW7axVmzG3ZJM7CWWPKbVv2bID\nSRB2IAnCDiRB2IEkCDuQBGEHkiDsQBI3fJ99asZoE7f6rsGQw67eSOfRWBVs2YEkCDuQBGEHkiDs\nQBKEHUiCsANJbOn87AtbmX1V0rsbbrpD0vtLK6Af9ZRNrR5pejWNXc+fRsT2ze5Yatj/38rtWUQU\nzju5XNRTNrV6pOnVNLV6NmI3HkiCsANJjB32wyOv/3rUUza1eqTp1TS1en5v1PfsAJZn7C07gCUZ\nJey277f9P7bftv3kGDVcV89522/aPml7NlINR2xfsX16w2232z5m+63u320j13PI9sVunE7a3r/E\nenbbfsX2WdtnbD/e3T7KGBXqGW2M+ix9N972TZJ+Jemrki5Iel3SIxFxdqmF/GFN5yWtRcRo/VHb\nfyXpY0n/EhFf7m77R0kfRMRT3X+K2yLi70es55CkjyPi6WXUcF09OyXtjIg3bN8m6YSkByX9nUYY\no0I9D2ukMeozxpb9HklvR8Q7EfFbST+S9MAIdUxKRLwq6YPrbn5A0tHu+lGt/zGNWc9oIuJSRLzR\nXf9I0jlJuzTSGBXqmawxwr5L0m82/HxB4w9SSPql7RO2D45cy0Y7IuJSd/09STvGLKbzmO1T3W7+\n0t5WbGR7j6S7Jb2mCYzRdfVIExijzfAB3bp7I+IvJP2tpG91u7CTEuvvt8ZunTwn6U5JeyVdkvTM\nsguwfaukFyU9EREfbrxvjDHapJ7Rx2ieMcJ+UdLuDT9/obttNBFxsfv3iqSfav2txhRc7t4bXnuP\neGXMYiLickR8GhG/k/R9LXmcbN+s9WD9MCJ+0t082hhtVs/YY1QyRthfl3SX7S/a/rykr0t6eYQ6\nJEm2b+k+YJHtWyR9TdLp8qOW5mVJB7rrByS9NGIt18J0zUNa4jjZtqTnJZ2LiGc33DXKGM2rZ8wx\n6hURS79I2q/1T+R/LekfxqhhQy1/Jum/usuZseqR9ILWd/v+V+ufYzwq6Y8lHZf0lqT/kHT7yPX8\nq6Q3JZ3Sesh2LrGee7W+i35K0snusn+sMSrUM9oY9V34Bh2QBB/QAUkQdiAJwg4kQdiBJAg7kARh\nB5Ig7EAShB1I4v8Az6bc/1zJGeEAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQh3zENZRF5_"
      },
      "source": [
        "L0= listeT0 (30)\n",
        "\n",
        "def listeT200 (L0,N): # we create a list of arrays having undergone an evolution from the list L0 according to the new rule\n",
        "  L200=[]           \n",
        "  for k in L0:\n",
        "    L200.append(evolution2(k,N))\n",
        "  return (L200)\n",
        "\n",
        "L200 = listeT200 (L0,30) # L200 corresponds to the end list of L0 according to the new rule\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_Ck4BD4-TFiW",
        "outputId": "8af40b7b-88ed-4347-b30f-8b8c5ff2caab",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "L1,L40=shapem (L0,L200) # L1 et L40 sont les versions compatibles de L0 et L200 avec Conv2D\n",
        "\n",
        "print (L1.shape)\n",
        "print(L40.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1000, 30, 30, 1)\n",
            "(1000, 30, 30, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iPWXCsynSksv",
        "outputId": "cee76455-4034-40d9-f578-c066983a9d8f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "\n",
        "rnvide3 = Sequential() # We recreate our new neural network\n",
        "Depay=Conv2D(1, (3, 3), input_shape=(N, N, 1) , padding='same', activation='tanh')\n",
        "rnvide3.add(Depay)\n",
        "\n",
        "\n",
        "rnvide3.compile(loss='mse', optimizer='adadelta', metrics=['accuracy']) \n",
        "rnvide3.fit(x=L1, y=L40, batch_size=64, epochs=68, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/68\n",
            "1000/1000 [==============================] - 0s 220us/step - loss: 0.8035 - acc: 0.3560\n",
            "Epoch 2/68\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.7446 - acc: 0.3718\n",
            "Epoch 3/68\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.6857 - acc: 0.3874\n",
            "Epoch 4/68\n",
            "1000/1000 [==============================] - 0s 44us/step - loss: 0.6280 - acc: 0.4038\n",
            "Epoch 5/68\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.5723 - acc: 0.4192\n",
            "Epoch 6/68\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.5203 - acc: 0.4347\n",
            "Epoch 7/68\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.4729 - acc: 0.4504\n",
            "Epoch 8/68\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.4310 - acc: 0.4665\n",
            "Epoch 9/68\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.3945 - acc: 0.4837\n",
            "Epoch 10/68\n",
            "1000/1000 [==============================] - 0s 45us/step - loss: 0.3630 - acc: 0.5020\n",
            "Epoch 11/68\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.3358 - acc: 0.5199\n",
            "Epoch 12/68\n",
            "1000/1000 [==============================] - 0s 68us/step - loss: 0.3122 - acc: 0.5390\n",
            "Epoch 13/68\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.2917 - acc: 0.5598\n",
            "Epoch 14/68\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.2738 - acc: 0.5803\n",
            "Epoch 15/68\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.2581 - acc: 0.5985\n",
            "Epoch 16/68\n",
            "1000/1000 [==============================] - 0s 51us/step - loss: 0.2442 - acc: 0.6163\n",
            "Epoch 17/68\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.2317 - acc: 0.6347\n",
            "Epoch 18/68\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.2206 - acc: 0.6495\n",
            "Epoch 19/68\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.2106 - acc: 0.6648\n",
            "Epoch 20/68\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.2016 - acc: 0.6794\n",
            "Epoch 21/68\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1934 - acc: 0.6941\n",
            "Epoch 22/68\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1859 - acc: 0.7053\n",
            "Epoch 23/68\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1791 - acc: 0.7142\n",
            "Epoch 24/68\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.1728 - acc: 0.7253\n",
            "Epoch 25/68\n",
            "1000/1000 [==============================] - 0s 60us/step - loss: 0.1671 - acc: 0.7340\n",
            "Epoch 26/68\n",
            "1000/1000 [==============================] - 0s 64us/step - loss: 0.1618 - acc: 0.7415\n",
            "Epoch 27/68\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.1570 - acc: 0.7546\n",
            "Epoch 28/68\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.1525 - acc: 0.7677\n",
            "Epoch 29/68\n",
            "1000/1000 [==============================] - 0s 45us/step - loss: 0.1483 - acc: 0.7826\n",
            "Epoch 30/68\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.1445 - acc: 0.7988\n",
            "Epoch 31/68\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.1410 - acc: 0.8163\n",
            "Epoch 32/68\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.1378 - acc: 0.8311\n",
            "Epoch 33/68\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1347 - acc: 0.8409\n",
            "Epoch 34/68\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.1320 - acc: 0.8478\n",
            "Epoch 35/68\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1294 - acc: 0.8532\n",
            "Epoch 36/68\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.1270 - acc: 0.8545\n",
            "Epoch 37/68\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1248 - acc: 0.8545\n",
            "Epoch 38/68\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1228 - acc: 0.8545\n",
            "Epoch 39/68\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.1209 - acc: 0.8545\n",
            "Epoch 40/68\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.1192 - acc: 0.8545\n",
            "Epoch 41/68\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.1176 - acc: 0.8545\n",
            "Epoch 42/68\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.1162 - acc: 0.8545\n",
            "Epoch 43/68\n",
            "1000/1000 [==============================] - 0s 55us/step - loss: 0.1148 - acc: 0.8545\n",
            "Epoch 44/68\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.1136 - acc: 0.8545\n",
            "Epoch 45/68\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.1125 - acc: 0.8545\n",
            "Epoch 46/68\n",
            "1000/1000 [==============================] - 0s 45us/step - loss: 0.1114 - acc: 0.8545\n",
            "Epoch 47/68\n",
            "1000/1000 [==============================] - 0s 55us/step - loss: 0.1105 - acc: 0.8545\n",
            "Epoch 48/68\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.1096 - acc: 0.8545\n",
            "Epoch 49/68\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.1088 - acc: 0.8545\n",
            "Epoch 50/68\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.1081 - acc: 0.8545\n",
            "Epoch 51/68\n",
            "1000/1000 [==============================] - 0s 47us/step - loss: 0.1075 - acc: 0.8545\n",
            "Epoch 52/68\n",
            "1000/1000 [==============================] - 0s 63us/step - loss: 0.1069 - acc: 0.8545\n",
            "Epoch 53/68\n",
            "1000/1000 [==============================] - 0s 56us/step - loss: 0.1064 - acc: 0.8545\n",
            "Epoch 54/68\n",
            "1000/1000 [==============================] - 0s 53us/step - loss: 0.1059 - acc: 0.8545\n",
            "Epoch 55/68\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.1055 - acc: 0.8545\n",
            "Epoch 56/68\n",
            "1000/1000 [==============================] - 0s 48us/step - loss: 0.1051 - acc: 0.8545\n",
            "Epoch 57/68\n",
            "1000/1000 [==============================] - 0s 45us/step - loss: 0.1047 - acc: 0.8545\n",
            "Epoch 58/68\n",
            "1000/1000 [==============================] - 0s 46us/step - loss: 0.1044 - acc: 0.8545\n",
            "Epoch 59/68\n",
            "1000/1000 [==============================] - 0s 49us/step - loss: 0.1042 - acc: 0.8545\n",
            "Epoch 60/68\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1039 - acc: 0.8545\n",
            "Epoch 61/68\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.1037 - acc: 0.8545\n",
            "Epoch 62/68\n",
            "1000/1000 [==============================] - 0s 44us/step - loss: 0.1036 - acc: 0.8545\n",
            "Epoch 63/68\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1034 - acc: 0.8545\n",
            "Epoch 64/68\n",
            "1000/1000 [==============================] - 0s 55us/step - loss: 0.1033 - acc: 0.8545\n",
            "Epoch 65/68\n",
            "1000/1000 [==============================] - 0s 52us/step - loss: 0.1032 - acc: 0.8542\n",
            "Epoch 66/68\n",
            "1000/1000 [==============================] - 0s 54us/step - loss: 0.1031 - acc: 0.8543\n",
            "Epoch 67/68\n",
            "1000/1000 [==============================] - 0s 60us/step - loss: 0.1030 - acc: 0.8542\n",
            "Epoch 68/68\n",
            "1000/1000 [==============================] - 0s 50us/step - loss: 0.1030 - acc: 0.8531\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6e660302b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PnJ2OqI2T2q5",
        "outputId": "31d216e6-7c6c-42f5-d099-221672cf0e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "def fonction3 (T,N): # This function makes the table evolve to the final state with the new rule\n",
        "  T1= T\n",
        "  a=0\n",
        "  for i in range (10000):\n",
        "    T1= evolution2 (T,N)\n",
        "    if (T==T1).all()== True:\n",
        "      a=i\n",
        "      break\n",
        "    else: \n",
        "      T=T1\n",
        "  return (T1)\n",
        "\n",
        "def fonction4 (T,N):# the function returns the number of evolutions before the table is stabilized with the new rule\n",
        "  T1= T\n",
        "  a=0\n",
        "  for i in range (1000):\n",
        "    T1= evolution2 (T,N)\n",
        "    if (T==T1).all()== True:\n",
        "      a=i\n",
        "      break\n",
        "    else: \n",
        "      T=T1\n",
        "  return (a)\n",
        "\n",
        "T10000= fonction4(T0,N)\n",
        "print (T10000)\n",
        "\n",
        "def listeT10000 (L0,N): # This function returns the list of the evolution number of each array before stabilization\n",
        "  L10000=[]\n",
        "  for k in L0:\n",
        "    L10000.append(fonction4(k,N))\n",
        "  return (L10000)\n",
        "\n",
        "L10000=listeT10000 (L0,N)\n",
        "\n",
        "m = max(L10000)     \n",
        "n= mean (L10000) \n",
        "print (m)\n",
        "print (n)\n",
        "o= int(n) # o is the average number of evolutions\n",
        "print (o)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "16\n",
            "44\n",
            "17.56\n",
            "17\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zy3kO5gVZZ6"
      },
      "source": [
        "def listeT2000 (L0,N):\n",
        "  L2000=[]\n",
        "  for k in L0:\n",
        "    L2000.append(fonction3(k,N))\n",
        "  return (L2000)\n",
        "\n",
        "L2000= listeT2000 (L0, N) # L2000 is the table list in the final state with the new rule\n",
        "\n",
        "L1,L50=shapem (L0,L2000) # L1 and L50 are the compatible versions of L0 and L2000 with Conv2D"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkQe4YyLWYNA",
        "outputId": "36da86d8-4ca9-4028-b8fc-0b75412c7409",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rnvide4= Sequential() # We create our second neural network\n",
        "rnvide4.add(Conv2D(1, (3, 3), input_shape=(N, N, 1) , padding='same', activation='tanh')) # First convolution\n",
        "for k in range (o): # We add o convolutions\n",
        "  rnvide4.add(Conv2D(1, (3, 3), padding='same', activation='tanh'))\n",
        "\n",
        "rnvide4.compile(loss='mse', optimizer='adadelta', metrics=['accuracy'])\n",
        "rnvide4.fit(x=L1, y=L50, batch_size=64, epochs=300, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1000/1000 [==============================] - 1s 1ms/step - loss: 1.0227 - acc: 0.0048\n",
            "Epoch 2/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 1.0019 - acc: 0.0044\n",
            "Epoch 3/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.9973 - acc: 0.0044\n",
            "Epoch 4/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.9963 - acc: 0.0044\n",
            "Epoch 5/300\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.9960 - acc: 0.0044\n",
            "Epoch 6/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.9958 - acc: 0.0044\n",
            "Epoch 7/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.9957 - acc: 0.0044\n",
            "Epoch 8/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.9957 - acc: 0.0044\n",
            "Epoch 9/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.9956 - acc: 0.0044\n",
            "Epoch 10/300\n",
            "1000/1000 [==============================] - 0s 195us/step - loss: 0.9956 - acc: 0.0044\n",
            "Epoch 11/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.9955 - acc: 0.0044\n",
            "Epoch 12/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.9955 - acc: 0.0044\n",
            "Epoch 13/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.9954 - acc: 0.0044\n",
            "Epoch 14/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.9954 - acc: 0.0044\n",
            "Epoch 15/300\n",
            "1000/1000 [==============================] - 0s 203us/step - loss: 0.9953 - acc: 0.0044\n",
            "Epoch 16/300\n",
            "1000/1000 [==============================] - 0s 200us/step - loss: 0.9952 - acc: 0.0044\n",
            "Epoch 17/300\n",
            "1000/1000 [==============================] - 0s 194us/step - loss: 0.9951 - acc: 0.0044\n",
            "Epoch 18/300\n",
            "1000/1000 [==============================] - 0s 210us/step - loss: 0.9948 - acc: 0.0044\n",
            "Epoch 19/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.9945 - acc: 0.0044\n",
            "Epoch 20/300\n",
            "1000/1000 [==============================] - 0s 209us/step - loss: 0.9939 - acc: 0.0044\n",
            "Epoch 21/300\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.9925 - acc: 0.0044\n",
            "Epoch 22/300\n",
            "1000/1000 [==============================] - 0s 194us/step - loss: 0.9873 - acc: 0.0044\n",
            "Epoch 23/300\n",
            "1000/1000 [==============================] - 0s 195us/step - loss: 0.8908 - acc: 0.0877\n",
            "Epoch 24/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.4519 - acc: 0.6553\n",
            "Epoch 25/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.3247 - acc: 0.7961\n",
            "Epoch 26/300\n",
            "1000/1000 [==============================] - 0s 206us/step - loss: 0.3022 - acc: 0.8129\n",
            "Epoch 27/300\n",
            "1000/1000 [==============================] - 0s 195us/step - loss: 0.2845 - acc: 0.8231\n",
            "Epoch 28/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.2851 - acc: 0.8243\n",
            "Epoch 29/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.2714 - acc: 0.8311\n",
            "Epoch 30/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.2683 - acc: 0.8352\n",
            "Epoch 31/300\n",
            "1000/1000 [==============================] - 0s 199us/step - loss: 0.2666 - acc: 0.8379\n",
            "Epoch 32/300\n",
            "1000/1000 [==============================] - 0s 188us/step - loss: 0.2659 - acc: 0.8389\n",
            "Epoch 33/300\n",
            "1000/1000 [==============================] - 0s 200us/step - loss: 0.2596 - acc: 0.8422\n",
            "Epoch 34/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.2654 - acc: 0.8408\n",
            "Epoch 35/300\n",
            "1000/1000 [==============================] - 0s 200us/step - loss: 0.2525 - acc: 0.8458\n",
            "Epoch 36/300\n",
            "1000/1000 [==============================] - 0s 199us/step - loss: 0.2534 - acc: 0.8469\n",
            "Epoch 37/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.2551 - acc: 0.8465\n",
            "Epoch 38/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.2495 - acc: 0.8488\n",
            "Epoch 39/300\n",
            "1000/1000 [==============================] - 0s 193us/step - loss: 0.2537 - acc: 0.8477\n",
            "Epoch 40/300\n",
            "1000/1000 [==============================] - 0s 202us/step - loss: 0.2495 - acc: 0.8489\n",
            "Epoch 41/300\n",
            "1000/1000 [==============================] - 0s 194us/step - loss: 0.2456 - acc: 0.8508\n",
            "Epoch 42/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.2403 - acc: 0.8537\n",
            "Epoch 43/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.2411 - acc: 0.8538\n",
            "Epoch 44/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.2411 - acc: 0.8543\n",
            "Epoch 45/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.2421 - acc: 0.8541\n",
            "Epoch 46/300\n",
            "1000/1000 [==============================] - 0s 200us/step - loss: 0.2380 - acc: 0.8555\n",
            "Epoch 47/300\n",
            "1000/1000 [==============================] - 0s 187us/step - loss: 0.2369 - acc: 0.8565\n",
            "Epoch 48/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.2403 - acc: 0.8549\n",
            "Epoch 49/300\n",
            "1000/1000 [==============================] - 0s 198us/step - loss: 0.2323 - acc: 0.8579\n",
            "Epoch 50/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.2365 - acc: 0.8566\n",
            "Epoch 51/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.2388 - acc: 0.8556\n",
            "Epoch 52/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.2357 - acc: 0.8567\n",
            "Epoch 53/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.2328 - acc: 0.8576\n",
            "Epoch 54/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.2357 - acc: 0.8567\n",
            "Epoch 55/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.2326 - acc: 0.8574\n",
            "Epoch 56/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.2284 - acc: 0.8591\n",
            "Epoch 57/300\n",
            "1000/1000 [==============================] - 0s 204us/step - loss: 0.2266 - acc: 0.8603\n",
            "Epoch 58/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.2307 - acc: 0.8584\n",
            "Epoch 59/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.2278 - acc: 0.8600\n",
            "Epoch 60/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.2302 - acc: 0.8585\n",
            "Epoch 61/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.2322 - acc: 0.8578\n",
            "Epoch 62/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.2220 - acc: 0.8615\n",
            "Epoch 63/300\n",
            "1000/1000 [==============================] - 0s 199us/step - loss: 0.2252 - acc: 0.8603\n",
            "Epoch 64/300\n",
            "1000/1000 [==============================] - 0s 200us/step - loss: 0.2244 - acc: 0.8608\n",
            "Epoch 65/300\n",
            "1000/1000 [==============================] - 0s 198us/step - loss: 0.2250 - acc: 0.8599\n",
            "Epoch 66/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.2247 - acc: 0.8604\n",
            "Epoch 67/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.2239 - acc: 0.8604\n",
            "Epoch 68/300\n",
            "1000/1000 [==============================] - 0s 202us/step - loss: 0.2175 - acc: 0.8629\n",
            "Epoch 69/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.2204 - acc: 0.8619\n",
            "Epoch 70/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.2197 - acc: 0.8626\n",
            "Epoch 71/300\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.2214 - acc: 0.8615\n",
            "Epoch 72/300\n",
            "1000/1000 [==============================] - 0s 194us/step - loss: 0.2160 - acc: 0.8634\n",
            "Epoch 73/300\n",
            "1000/1000 [==============================] - 0s 200us/step - loss: 0.2192 - acc: 0.8624\n",
            "Epoch 74/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.2158 - acc: 0.8635\n",
            "Epoch 75/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.2177 - acc: 0.8628\n",
            "Epoch 76/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.2107 - acc: 0.8658\n",
            "Epoch 77/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.2155 - acc: 0.8635\n",
            "Epoch 78/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.2145 - acc: 0.8645\n",
            "Epoch 79/300\n",
            "1000/1000 [==============================] - 0s 187us/step - loss: 0.2159 - acc: 0.8637\n",
            "Epoch 80/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.2110 - acc: 0.8654\n",
            "Epoch 81/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.2099 - acc: 0.8661\n",
            "Epoch 82/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.2125 - acc: 0.8652\n",
            "Epoch 83/300\n",
            "1000/1000 [==============================] - 0s 174us/step - loss: 0.2095 - acc: 0.8667\n",
            "Epoch 84/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.2102 - acc: 0.8663\n",
            "Epoch 85/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.2116 - acc: 0.8660\n",
            "Epoch 86/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.2062 - acc: 0.8677\n",
            "Epoch 87/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.2112 - acc: 0.8665\n",
            "Epoch 88/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.2056 - acc: 0.8689\n",
            "Epoch 89/300\n",
            "1000/1000 [==============================] - 0s 170us/step - loss: 0.2046 - acc: 0.8689\n",
            "Epoch 90/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.2069 - acc: 0.8680\n",
            "Epoch 91/300\n",
            "1000/1000 [==============================] - 0s 199us/step - loss: 0.2048 - acc: 0.8691\n",
            "Epoch 92/300\n",
            "1000/1000 [==============================] - 0s 188us/step - loss: 0.2028 - acc: 0.8701\n",
            "Epoch 93/300\n",
            "1000/1000 [==============================] - 0s 193us/step - loss: 0.2015 - acc: 0.8708\n",
            "Epoch 94/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.2011 - acc: 0.8710\n",
            "Epoch 95/300\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.2057 - acc: 0.8692\n",
            "Epoch 96/300\n",
            "1000/1000 [==============================] - 0s 206us/step - loss: 0.2000 - acc: 0.8718\n",
            "Epoch 97/300\n",
            "1000/1000 [==============================] - 0s 188us/step - loss: 0.1997 - acc: 0.8720\n",
            "Epoch 98/300\n",
            "1000/1000 [==============================] - 0s 195us/step - loss: 0.2000 - acc: 0.8721\n",
            "Epoch 99/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.1991 - acc: 0.8724\n",
            "Epoch 100/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.1998 - acc: 0.8723\n",
            "Epoch 101/300\n",
            "1000/1000 [==============================] - 0s 199us/step - loss: 0.1984 - acc: 0.8731\n",
            "Epoch 102/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1993 - acc: 0.8729\n",
            "Epoch 103/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.1981 - acc: 0.8731\n",
            "Epoch 104/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1973 - acc: 0.8738\n",
            "Epoch 105/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.1981 - acc: 0.8739\n",
            "Epoch 106/300\n",
            "1000/1000 [==============================] - 0s 198us/step - loss: 0.1972 - acc: 0.8740\n",
            "Epoch 107/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.1963 - acc: 0.8744\n",
            "Epoch 108/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.1962 - acc: 0.8747\n",
            "Epoch 109/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.1956 - acc: 0.8750\n",
            "Epoch 110/300\n",
            "1000/1000 [==============================] - 0s 193us/step - loss: 0.1954 - acc: 0.8753\n",
            "Epoch 111/300\n",
            "1000/1000 [==============================] - 0s 205us/step - loss: 0.1949 - acc: 0.8755\n",
            "Epoch 112/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1951 - acc: 0.8756\n",
            "Epoch 113/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1947 - acc: 0.8761\n",
            "Epoch 114/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.1946 - acc: 0.8760\n",
            "Epoch 115/300\n",
            "1000/1000 [==============================] - 0s 209us/step - loss: 0.1940 - acc: 0.8763\n",
            "Epoch 116/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.1938 - acc: 0.8764\n",
            "Epoch 117/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.1941 - acc: 0.8760\n",
            "Epoch 118/300\n",
            "1000/1000 [==============================] - 0s 193us/step - loss: 0.1931 - acc: 0.8768\n",
            "Epoch 119/300\n",
            "1000/1000 [==============================] - 0s 188us/step - loss: 0.1931 - acc: 0.8772\n",
            "Epoch 120/300\n",
            "1000/1000 [==============================] - 0s 198us/step - loss: 0.1928 - acc: 0.8773\n",
            "Epoch 121/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.1931 - acc: 0.8773\n",
            "Epoch 122/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.1923 - acc: 0.8774\n",
            "Epoch 123/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1922 - acc: 0.8776\n",
            "Epoch 124/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.1918 - acc: 0.8783\n",
            "Epoch 125/300\n",
            "1000/1000 [==============================] - 0s 188us/step - loss: 0.1918 - acc: 0.8781\n",
            "Epoch 126/300\n",
            "1000/1000 [==============================] - 0s 193us/step - loss: 0.1915 - acc: 0.8781\n",
            "Epoch 127/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1914 - acc: 0.8783\n",
            "Epoch 128/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1914 - acc: 0.8786\n",
            "Epoch 129/300\n",
            "1000/1000 [==============================] - 0s 187us/step - loss: 0.1908 - acc: 0.8786\n",
            "Epoch 130/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1906 - acc: 0.8790\n",
            "Epoch 131/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.1906 - acc: 0.8792\n",
            "Epoch 132/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.1902 - acc: 0.8791\n",
            "Epoch 133/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1899 - acc: 0.8796\n",
            "Epoch 134/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.1902 - acc: 0.8794\n",
            "Epoch 135/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1897 - acc: 0.8796\n",
            "Epoch 136/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1895 - acc: 0.8797\n",
            "Epoch 137/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.1892 - acc: 0.8798\n",
            "Epoch 138/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.1893 - acc: 0.8799\n",
            "Epoch 139/300\n",
            "1000/1000 [==============================] - 0s 187us/step - loss: 0.1889 - acc: 0.8805\n",
            "Epoch 140/300\n",
            "1000/1000 [==============================] - 0s 202us/step - loss: 0.1891 - acc: 0.8806\n",
            "Epoch 141/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.1888 - acc: 0.8803\n",
            "Epoch 142/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.1883 - acc: 0.8809\n",
            "Epoch 143/300\n",
            "1000/1000 [==============================] - 0s 199us/step - loss: 0.1881 - acc: 0.8809\n",
            "Epoch 144/300\n",
            "1000/1000 [==============================] - 0s 202us/step - loss: 0.1878 - acc: 0.8808\n",
            "Epoch 145/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.1881 - acc: 0.8811\n",
            "Epoch 146/300\n",
            "1000/1000 [==============================] - 0s 194us/step - loss: 0.1876 - acc: 0.8814\n",
            "Epoch 147/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.1875 - acc: 0.8814\n",
            "Epoch 148/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.1874 - acc: 0.8815\n",
            "Epoch 149/300\n",
            "1000/1000 [==============================] - 0s 212us/step - loss: 0.1872 - acc: 0.8814\n",
            "Epoch 150/300\n",
            "1000/1000 [==============================] - 0s 202us/step - loss: 0.1872 - acc: 0.8816\n",
            "Epoch 151/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1869 - acc: 0.8815\n",
            "Epoch 152/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1866 - acc: 0.8821\n",
            "Epoch 153/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.1867 - acc: 0.8823\n",
            "Epoch 154/300\n",
            "1000/1000 [==============================] - 0s 199us/step - loss: 0.1863 - acc: 0.8820\n",
            "Epoch 155/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.1865 - acc: 0.8821\n",
            "Epoch 156/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.1863 - acc: 0.8826\n",
            "Epoch 157/300\n",
            "1000/1000 [==============================] - 0s 202us/step - loss: 0.1860 - acc: 0.8825\n",
            "Epoch 158/300\n",
            "1000/1000 [==============================] - 0s 198us/step - loss: 0.1861 - acc: 0.8823\n",
            "Epoch 159/300\n",
            "1000/1000 [==============================] - 0s 203us/step - loss: 0.1859 - acc: 0.8825\n",
            "Epoch 160/300\n",
            "1000/1000 [==============================] - 0s 188us/step - loss: 0.1857 - acc: 0.8830\n",
            "Epoch 161/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1856 - acc: 0.8828\n",
            "Epoch 162/300\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.1850 - acc: 0.8830\n",
            "Epoch 163/300\n",
            "1000/1000 [==============================] - 0s 206us/step - loss: 0.1852 - acc: 0.8831\n",
            "Epoch 164/300\n",
            "1000/1000 [==============================] - 0s 214us/step - loss: 0.1850 - acc: 0.8830\n",
            "Epoch 165/300\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.1848 - acc: 0.8833\n",
            "Epoch 166/300\n",
            "1000/1000 [==============================] - 0s 200us/step - loss: 0.1846 - acc: 0.8834\n",
            "Epoch 167/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.1845 - acc: 0.8837\n",
            "Epoch 168/300\n",
            "1000/1000 [==============================] - 0s 198us/step - loss: 0.1844 - acc: 0.8838\n",
            "Epoch 169/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.1843 - acc: 0.8836\n",
            "Epoch 170/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.1840 - acc: 0.8836\n",
            "Epoch 171/300\n",
            "1000/1000 [==============================] - 0s 188us/step - loss: 0.1841 - acc: 0.8842\n",
            "Epoch 172/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.1837 - acc: 0.8838\n",
            "Epoch 173/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.1839 - acc: 0.8839\n",
            "Epoch 174/300\n",
            "1000/1000 [==============================] - 0s 201us/step - loss: 0.1835 - acc: 0.8844\n",
            "Epoch 175/300\n",
            "1000/1000 [==============================] - 0s 211us/step - loss: 0.1833 - acc: 0.8845\n",
            "Epoch 176/300\n",
            "1000/1000 [==============================] - 0s 195us/step - loss: 0.1834 - acc: 0.8843\n",
            "Epoch 177/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1830 - acc: 0.8849\n",
            "Epoch 178/300\n",
            "1000/1000 [==============================] - 0s 204us/step - loss: 0.1830 - acc: 0.8843\n",
            "Epoch 179/300\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.1830 - acc: 0.8847\n",
            "Epoch 180/300\n",
            "1000/1000 [==============================] - 0s 209us/step - loss: 0.1828 - acc: 0.8849\n",
            "Epoch 181/300\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.1826 - acc: 0.8848\n",
            "Epoch 182/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.1823 - acc: 0.8852\n",
            "Epoch 183/300\n",
            "1000/1000 [==============================] - 0s 195us/step - loss: 0.1829 - acc: 0.8851\n",
            "Epoch 184/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.1823 - acc: 0.8851\n",
            "Epoch 185/300\n",
            "1000/1000 [==============================] - 0s 207us/step - loss: 0.1820 - acc: 0.8854\n",
            "Epoch 186/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.1819 - acc: 0.8855\n",
            "Epoch 187/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1820 - acc: 0.8856\n",
            "Epoch 188/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1815 - acc: 0.8858\n",
            "Epoch 189/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1814 - acc: 0.8858\n",
            "Epoch 190/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1816 - acc: 0.8855\n",
            "Epoch 191/300\n",
            "1000/1000 [==============================] - 0s 207us/step - loss: 0.1812 - acc: 0.8858\n",
            "Epoch 192/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1810 - acc: 0.8859\n",
            "Epoch 193/300\n",
            "1000/1000 [==============================] - 0s 170us/step - loss: 0.1812 - acc: 0.8862\n",
            "Epoch 194/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1807 - acc: 0.8863\n",
            "Epoch 195/300\n",
            "1000/1000 [==============================] - 0s 178us/step - loss: 0.1805 - acc: 0.8866\n",
            "Epoch 196/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.1804 - acc: 0.8865\n",
            "Epoch 197/300\n",
            "1000/1000 [==============================] - 0s 199us/step - loss: 0.1801 - acc: 0.8867\n",
            "Epoch 198/300\n",
            "1000/1000 [==============================] - 0s 193us/step - loss: 0.1801 - acc: 0.8869\n",
            "Epoch 199/300\n",
            "1000/1000 [==============================] - 0s 187us/step - loss: 0.1801 - acc: 0.8869\n",
            "Epoch 200/300\n",
            "1000/1000 [==============================] - 0s 199us/step - loss: 0.1798 - acc: 0.8871\n",
            "Epoch 201/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1798 - acc: 0.8872\n",
            "Epoch 202/300\n",
            "1000/1000 [==============================] - 0s 188us/step - loss: 0.1794 - acc: 0.8870\n",
            "Epoch 203/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.1796 - acc: 0.8873\n",
            "Epoch 204/300\n",
            "1000/1000 [==============================] - 0s 167us/step - loss: 0.1791 - acc: 0.8877\n",
            "Epoch 205/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.1791 - acc: 0.8877\n",
            "Epoch 206/300\n",
            "1000/1000 [==============================] - 0s 170us/step - loss: 0.1789 - acc: 0.8881\n",
            "Epoch 207/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.1787 - acc: 0.8880\n",
            "Epoch 208/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1785 - acc: 0.8882\n",
            "Epoch 209/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1781 - acc: 0.8883\n",
            "Epoch 210/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.1780 - acc: 0.8884\n",
            "Epoch 211/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.1778 - acc: 0.8887\n",
            "Epoch 212/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1777 - acc: 0.8891\n",
            "Epoch 213/300\n",
            "1000/1000 [==============================] - 0s 188us/step - loss: 0.1775 - acc: 0.8887\n",
            "Epoch 214/300\n",
            "1000/1000 [==============================] - 0s 202us/step - loss: 0.1773 - acc: 0.8890\n",
            "Epoch 215/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1771 - acc: 0.8895\n",
            "Epoch 216/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.1769 - acc: 0.8891\n",
            "Epoch 217/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1769 - acc: 0.8898\n",
            "Epoch 218/300\n",
            "1000/1000 [==============================] - 0s 199us/step - loss: 0.1765 - acc: 0.8899\n",
            "Epoch 219/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.1767 - acc: 0.8900\n",
            "Epoch 220/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.1762 - acc: 0.8904\n",
            "Epoch 221/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1763 - acc: 0.8900\n",
            "Epoch 222/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1759 - acc: 0.8908\n",
            "Epoch 223/300\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.1758 - acc: 0.8904\n",
            "Epoch 224/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1758 - acc: 0.8904\n",
            "Epoch 225/300\n",
            "1000/1000 [==============================] - 0s 188us/step - loss: 0.1757 - acc: 0.8911\n",
            "Epoch 226/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1753 - acc: 0.8909\n",
            "Epoch 227/300\n",
            "1000/1000 [==============================] - 0s 183us/step - loss: 0.1755 - acc: 0.8911\n",
            "Epoch 228/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1753 - acc: 0.8907\n",
            "Epoch 229/300\n",
            "1000/1000 [==============================] - 0s 205us/step - loss: 0.1749 - acc: 0.8914\n",
            "Epoch 230/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.1747 - acc: 0.8916\n",
            "Epoch 231/300\n",
            "1000/1000 [==============================] - 0s 170us/step - loss: 0.1746 - acc: 0.8915\n",
            "Epoch 232/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.1749 - acc: 0.8917\n",
            "Epoch 233/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1746 - acc: 0.8915\n",
            "Epoch 234/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.1745 - acc: 0.8920\n",
            "Epoch 235/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1745 - acc: 0.8917\n",
            "Epoch 236/300\n",
            "1000/1000 [==============================] - 0s 172us/step - loss: 0.1741 - acc: 0.8922\n",
            "Epoch 237/300\n",
            "1000/1000 [==============================] - 0s 176us/step - loss: 0.1738 - acc: 0.8920\n",
            "Epoch 238/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.1738 - acc: 0.8925\n",
            "Epoch 239/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.1737 - acc: 0.8927\n",
            "Epoch 240/300\n",
            "1000/1000 [==============================] - 0s 201us/step - loss: 0.1735 - acc: 0.8926\n",
            "Epoch 241/300\n",
            "1000/1000 [==============================] - 0s 204us/step - loss: 0.1736 - acc: 0.8923\n",
            "Epoch 242/300\n",
            "1000/1000 [==============================] - 0s 205us/step - loss: 0.1736 - acc: 0.8929\n",
            "Epoch 243/300\n",
            "1000/1000 [==============================] - 0s 187us/step - loss: 0.1734 - acc: 0.8928\n",
            "Epoch 244/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.1732 - acc: 0.8930\n",
            "Epoch 245/300\n",
            "1000/1000 [==============================] - 0s 195us/step - loss: 0.1732 - acc: 0.8931\n",
            "Epoch 246/300\n",
            "1000/1000 [==============================] - 0s 190us/step - loss: 0.1728 - acc: 0.8930\n",
            "Epoch 247/300\n",
            "1000/1000 [==============================] - 0s 195us/step - loss: 0.1730 - acc: 0.8931\n",
            "Epoch 248/300\n",
            "1000/1000 [==============================] - 0s 200us/step - loss: 0.1730 - acc: 0.8936\n",
            "Epoch 249/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1727 - acc: 0.8936\n",
            "Epoch 250/300\n",
            "1000/1000 [==============================] - 0s 173us/step - loss: 0.1725 - acc: 0.8933\n",
            "Epoch 251/300\n",
            "1000/1000 [==============================] - 0s 201us/step - loss: 0.1726 - acc: 0.8935\n",
            "Epoch 252/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.1724 - acc: 0.8939\n",
            "Epoch 253/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.1721 - acc: 0.8938\n",
            "Epoch 254/300\n",
            "1000/1000 [==============================] - 0s 199us/step - loss: 0.1726 - acc: 0.8937\n",
            "Epoch 255/300\n",
            "1000/1000 [==============================] - 0s 198us/step - loss: 0.1720 - acc: 0.8940\n",
            "Epoch 256/300\n",
            "1000/1000 [==============================] - 0s 203us/step - loss: 0.1719 - acc: 0.8938\n",
            "Epoch 257/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1719 - acc: 0.8947\n",
            "Epoch 258/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.1717 - acc: 0.8941\n",
            "Epoch 259/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.1717 - acc: 0.8945\n",
            "Epoch 260/300\n",
            "1000/1000 [==============================] - 0s 181us/step - loss: 0.1716 - acc: 0.8943\n",
            "Epoch 261/300\n",
            "1000/1000 [==============================] - 0s 209us/step - loss: 0.1716 - acc: 0.8947\n",
            "Epoch 262/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.1714 - acc: 0.8945\n",
            "Epoch 263/300\n",
            "1000/1000 [==============================] - 0s 202us/step - loss: 0.1715 - acc: 0.8944\n",
            "Epoch 264/300\n",
            "1000/1000 [==============================] - 0s 204us/step - loss: 0.1712 - acc: 0.8951\n",
            "Epoch 265/300\n",
            "1000/1000 [==============================] - 0s 184us/step - loss: 0.1710 - acc: 0.8950\n",
            "Epoch 266/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.1710 - acc: 0.8949\n",
            "Epoch 267/300\n",
            "1000/1000 [==============================] - 0s 198us/step - loss: 0.1709 - acc: 0.8949\n",
            "Epoch 268/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.1708 - acc: 0.8953\n",
            "Epoch 269/300\n",
            "1000/1000 [==============================] - 0s 188us/step - loss: 0.1711 - acc: 0.8949\n",
            "Epoch 270/300\n",
            "1000/1000 [==============================] - 0s 180us/step - loss: 0.1706 - acc: 0.8954\n",
            "Epoch 271/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.1705 - acc: 0.8951\n",
            "Epoch 272/300\n",
            "1000/1000 [==============================] - 0s 200us/step - loss: 0.1707 - acc: 0.8953\n",
            "Epoch 273/300\n",
            "1000/1000 [==============================] - 0s 179us/step - loss: 0.1705 - acc: 0.8956\n",
            "Epoch 274/300\n",
            "1000/1000 [==============================] - 0s 182us/step - loss: 0.1705 - acc: 0.8948\n",
            "Epoch 275/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.1703 - acc: 0.8957\n",
            "Epoch 276/300\n",
            "1000/1000 [==============================] - 0s 171us/step - loss: 0.1700 - acc: 0.8952\n",
            "Epoch 277/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1700 - acc: 0.8957\n",
            "Epoch 278/300\n",
            "1000/1000 [==============================] - 0s 177us/step - loss: 0.1700 - acc: 0.8961\n",
            "Epoch 279/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.1698 - acc: 0.8960\n",
            "Epoch 280/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.1698 - acc: 0.8960\n",
            "Epoch 281/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.1699 - acc: 0.8955\n",
            "Epoch 282/300\n",
            "1000/1000 [==============================] - 0s 197us/step - loss: 0.1696 - acc: 0.8959\n",
            "Epoch 283/300\n",
            "1000/1000 [==============================] - 0s 196us/step - loss: 0.1696 - acc: 0.8962\n",
            "Epoch 284/300\n",
            "1000/1000 [==============================] - 0s 191us/step - loss: 0.1695 - acc: 0.8964\n",
            "Epoch 285/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.1699 - acc: 0.8963\n",
            "Epoch 286/300\n",
            "1000/1000 [==============================] - 0s 198us/step - loss: 0.1696 - acc: 0.8960\n",
            "Epoch 287/300\n",
            "1000/1000 [==============================] - 0s 189us/step - loss: 0.1692 - acc: 0.8966\n",
            "Epoch 288/300\n",
            "1000/1000 [==============================] - 0s 198us/step - loss: 0.1691 - acc: 0.8963\n",
            "Epoch 289/300\n",
            "1000/1000 [==============================] - 0s 194us/step - loss: 0.1694 - acc: 0.8965\n",
            "Epoch 290/300\n",
            "1000/1000 [==============================] - 0s 195us/step - loss: 0.1690 - acc: 0.8967\n",
            "Epoch 291/300\n",
            "1000/1000 [==============================] - 0s 195us/step - loss: 0.1691 - acc: 0.8967\n",
            "Epoch 292/300\n",
            "1000/1000 [==============================] - 0s 206us/step - loss: 0.1688 - acc: 0.8973\n",
            "Epoch 293/300\n",
            "1000/1000 [==============================] - 0s 214us/step - loss: 0.1691 - acc: 0.8963\n",
            "Epoch 294/300\n",
            "1000/1000 [==============================] - 0s 193us/step - loss: 0.1688 - acc: 0.8974\n",
            "Epoch 295/300\n",
            "1000/1000 [==============================] - 0s 205us/step - loss: 0.1687 - acc: 0.8975\n",
            "Epoch 296/300\n",
            "1000/1000 [==============================] - 0s 175us/step - loss: 0.1685 - acc: 0.8972\n",
            "Epoch 297/300\n",
            "1000/1000 [==============================] - 0s 186us/step - loss: 0.1684 - acc: 0.8969\n",
            "Epoch 298/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.1685 - acc: 0.8973\n",
            "Epoch 299/300\n",
            "1000/1000 [==============================] - 0s 185us/step - loss: 0.1683 - acc: 0.8975\n",
            "Epoch 300/300\n",
            "1000/1000 [==============================] - 0s 192us/step - loss: 0.1684 - acc: 0.8973\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f6e65e952b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrKdGSYeXDM4",
        "outputId": "4806f95e-b05d-47ef-eed7-28058521d980",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 782
        }
      },
      "source": [
        "H4=rnvide4.predict(L1, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
        "\n",
        "H5=np.around(H4) # H5 corresponds to the prediction of the evolution of L1 according to the new rule\n",
        "\n",
        "t=rd.randint (0,1001)\n",
        "print(t)\n",
        "\n",
        "im330 = MtoIm(L1[t],30)\n",
        "plt.imshow(im330)\n",
        "plt.show()\n",
        "\n",
        "im340 = MtoIm(L50[t],30)\n",
        "plt.imshow(im340)\n",
        "plt.show()\n",
        "\n",
        "im3500 = MtoIm(H5[t],30)\n",
        "plt.imshow(im3500)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "644\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nasKwS00YdqkJwy41YdilJgy71MT/AtFD5aoFijo2AAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Q8ecrrPZeqE",
        "outputId": "33bf7bc5-4d94-43d8-ea61-429b05f508c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "rnvide5= Sequential() # We create our final neural network\n",
        "rnvide5.add(Conv2D(50, (3, 3), input_shape=(N, N, 1) , padding='same', activation='tanh')) # This time with 50 filters\n",
        "for k in range (o-1): # We add o-1 convolutions to 50 filters each\n",
        "  rnvide5.add(Conv2D(50, (3, 3), padding='same', activation='tanh')) \n",
        "rnvide5.add(Conv2D(1, (3, 3), padding='same', activation='tanh')) \n",
        "# the last convolution must have a unique filter to be of good dimension\n",
        "\n",
        "rnvide5.compile(loss='mse', optimizer='adadelta', metrics=['accuracy'])\n",
        "rnvide5.fit(x=L1, y=L50, batch_size=64, epochs=300, verbose=1, callbacks=None, validation_split=0.0, validation_data=None, shuffle=True, class_weight=None, sample_weight=None, initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1, max_queue_size=10, workers=1, use_multiprocessing=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "1000/1000 [==============================] - 2s 2ms/step - loss: 0.8979 - acc: 0.6509\n",
            "Epoch 2/300\n",
            "1000/1000 [==============================] - 1s 800us/step - loss: 0.5134 - acc: 0.8241\n",
            "Epoch 3/300\n",
            "1000/1000 [==============================] - 1s 801us/step - loss: 0.4387 - acc: 0.8338\n",
            "Epoch 4/300\n",
            "1000/1000 [==============================] - 1s 800us/step - loss: 0.3785 - acc: 0.8393\n",
            "Epoch 5/300\n",
            "1000/1000 [==============================] - 1s 806us/step - loss: 0.3452 - acc: 0.8441\n",
            "Epoch 6/300\n",
            "1000/1000 [==============================] - 1s 809us/step - loss: 0.3274 - acc: 0.8441\n",
            "Epoch 7/300\n",
            "1000/1000 [==============================] - 1s 810us/step - loss: 0.2948 - acc: 0.8511\n",
            "Epoch 8/300\n",
            "1000/1000 [==============================] - 1s 805us/step - loss: 0.2910 - acc: 0.8487\n",
            "Epoch 9/300\n",
            "1000/1000 [==============================] - 1s 798us/step - loss: 0.2709 - acc: 0.8577\n",
            "Epoch 10/300\n",
            "1000/1000 [==============================] - 1s 804us/step - loss: 0.2648 - acc: 0.8563\n",
            "Epoch 11/300\n",
            "1000/1000 [==============================] - 1s 807us/step - loss: 0.2570 - acc: 0.8601\n",
            "Epoch 12/300\n",
            "1000/1000 [==============================] - 1s 796us/step - loss: 0.2471 - acc: 0.8612\n",
            "Epoch 13/300\n",
            "1000/1000 [==============================] - 1s 808us/step - loss: 0.2392 - acc: 0.8662\n",
            "Epoch 14/300\n",
            "1000/1000 [==============================] - 1s 800us/step - loss: 0.2423 - acc: 0.8635\n",
            "Epoch 15/300\n",
            "1000/1000 [==============================] - 1s 808us/step - loss: 0.2295 - acc: 0.8681\n",
            "Epoch 16/300\n",
            "1000/1000 [==============================] - 1s 801us/step - loss: 0.2286 - acc: 0.8693\n",
            "Epoch 17/300\n",
            "1000/1000 [==============================] - 1s 803us/step - loss: 0.2170 - acc: 0.8733\n",
            "Epoch 18/300\n",
            "1000/1000 [==============================] - 1s 812us/step - loss: 0.2202 - acc: 0.8737\n",
            "Epoch 19/300\n",
            "1000/1000 [==============================] - 1s 812us/step - loss: 0.2145 - acc: 0.8779\n",
            "Epoch 20/300\n",
            "1000/1000 [==============================] - 1s 811us/step - loss: 0.2082 - acc: 0.8793\n",
            "Epoch 21/300\n",
            "1000/1000 [==============================] - 1s 811us/step - loss: 0.2002 - acc: 0.8848\n",
            "Epoch 22/300\n",
            "1000/1000 [==============================] - 1s 807us/step - loss: 0.1937 - acc: 0.8873\n",
            "Epoch 23/300\n",
            "1000/1000 [==============================] - 1s 806us/step - loss: 0.1831 - acc: 0.8926\n",
            "Epoch 24/300\n",
            "1000/1000 [==============================] - 1s 809us/step - loss: 0.1788 - acc: 0.8967\n",
            "Epoch 25/300\n",
            "1000/1000 [==============================] - 1s 804us/step - loss: 0.1687 - acc: 0.9003\n",
            "Epoch 26/300\n",
            "1000/1000 [==============================] - 1s 805us/step - loss: 0.1714 - acc: 0.9006\n",
            "Epoch 27/300\n",
            "1000/1000 [==============================] - 1s 803us/step - loss: 0.1649 - acc: 0.9050\n",
            "Epoch 28/300\n",
            "1000/1000 [==============================] - 1s 812us/step - loss: 0.1545 - acc: 0.9096\n",
            "Epoch 29/300\n",
            "1000/1000 [==============================] - 1s 807us/step - loss: 0.1526 - acc: 0.9111\n",
            "Epoch 30/300\n",
            "1000/1000 [==============================] - 1s 800us/step - loss: 0.1519 - acc: 0.9126\n",
            "Epoch 31/300\n",
            "1000/1000 [==============================] - 1s 807us/step - loss: 0.1430 - acc: 0.9168\n",
            "Epoch 32/300\n",
            "1000/1000 [==============================] - 1s 801us/step - loss: 0.1462 - acc: 0.9166\n",
            "Epoch 33/300\n",
            "1000/1000 [==============================] - 1s 810us/step - loss: 0.1359 - acc: 0.9218\n",
            "Epoch 34/300\n",
            "1000/1000 [==============================] - 1s 810us/step - loss: 0.1341 - acc: 0.9238\n",
            "Epoch 35/300\n",
            "1000/1000 [==============================] - 1s 809us/step - loss: 0.1335 - acc: 0.9241\n",
            "Epoch 36/300\n",
            "1000/1000 [==============================] - 1s 816us/step - loss: 0.1331 - acc: 0.9255\n",
            "Epoch 37/300\n",
            "1000/1000 [==============================] - 1s 808us/step - loss: 0.1270 - acc: 0.9285\n",
            "Epoch 38/300\n",
            "1000/1000 [==============================] - 1s 815us/step - loss: 0.1274 - acc: 0.9290\n",
            "Epoch 39/300\n",
            "1000/1000 [==============================] - 1s 808us/step - loss: 0.1169 - acc: 0.9338\n",
            "Epoch 40/300\n",
            "1000/1000 [==============================] - 1s 812us/step - loss: 0.1203 - acc: 0.9334\n",
            "Epoch 41/300\n",
            "1000/1000 [==============================] - 1s 816us/step - loss: 0.1215 - acc: 0.9330\n",
            "Epoch 42/300\n",
            "1000/1000 [==============================] - 1s 842us/step - loss: 0.1190 - acc: 0.9347\n",
            "Epoch 43/300\n",
            "1000/1000 [==============================] - 1s 818us/step - loss: 0.1144 - acc: 0.9371\n",
            "Epoch 44/300\n",
            "1000/1000 [==============================] - 1s 808us/step - loss: 0.1134 - acc: 0.9372\n",
            "Epoch 45/300\n",
            "1000/1000 [==============================] - 1s 814us/step - loss: 0.1072 - acc: 0.9410\n",
            "Epoch 46/300\n",
            "1000/1000 [==============================] - 1s 807us/step - loss: 0.1127 - acc: 0.9390\n",
            "Epoch 47/300\n",
            "1000/1000 [==============================] - 1s 816us/step - loss: 0.1070 - acc: 0.9410\n",
            "Epoch 48/300\n",
            "1000/1000 [==============================] - 1s 818us/step - loss: 0.1066 - acc: 0.9421\n",
            "Epoch 49/300\n",
            "1000/1000 [==============================] - 1s 816us/step - loss: 0.1042 - acc: 0.9433\n",
            "Epoch 50/300\n",
            "1000/1000 [==============================] - 1s 811us/step - loss: 0.1026 - acc: 0.9440\n",
            "Epoch 51/300\n",
            "1000/1000 [==============================] - 1s 814us/step - loss: 0.1006 - acc: 0.9458\n",
            "Epoch 52/300\n",
            "1000/1000 [==============================] - 1s 814us/step - loss: 0.1019 - acc: 0.9450\n",
            "Epoch 53/300\n",
            "1000/1000 [==============================] - 1s 814us/step - loss: 0.0988 - acc: 0.9467\n",
            "Epoch 54/300\n",
            "1000/1000 [==============================] - 1s 809us/step - loss: 0.0983 - acc: 0.9479\n",
            "Epoch 55/300\n",
            "1000/1000 [==============================] - 1s 821us/step - loss: 0.0963 - acc: 0.9481\n",
            "Epoch 56/300\n",
            "1000/1000 [==============================] - 1s 814us/step - loss: 0.0944 - acc: 0.9496\n",
            "Epoch 57/300\n",
            "1000/1000 [==============================] - 1s 816us/step - loss: 0.0967 - acc: 0.9497\n",
            "Epoch 58/300\n",
            "1000/1000 [==============================] - 1s 834us/step - loss: 0.0899 - acc: 0.9516\n",
            "Epoch 59/300\n",
            "1000/1000 [==============================] - 1s 811us/step - loss: 0.0857 - acc: 0.9540\n",
            "Epoch 60/300\n",
            "1000/1000 [==============================] - 1s 805us/step - loss: 0.0963 - acc: 0.9498\n",
            "Epoch 61/300\n",
            "1000/1000 [==============================] - 1s 803us/step - loss: 0.0870 - acc: 0.9536\n",
            "Epoch 62/300\n",
            "1000/1000 [==============================] - 1s 815us/step - loss: 0.0879 - acc: 0.9538\n",
            "Epoch 63/300\n",
            "1000/1000 [==============================] - 1s 818us/step - loss: 0.0858 - acc: 0.9548\n",
            "Epoch 64/300\n",
            "1000/1000 [==============================] - 1s 816us/step - loss: 0.0874 - acc: 0.9541\n",
            "Epoch 65/300\n",
            "1000/1000 [==============================] - 1s 820us/step - loss: 0.0832 - acc: 0.9558\n",
            "Epoch 66/300\n",
            "1000/1000 [==============================] - 1s 827us/step - loss: 0.0905 - acc: 0.9534\n",
            "Epoch 67/300\n",
            "1000/1000 [==============================] - 1s 820us/step - loss: 0.0841 - acc: 0.9557\n",
            "Epoch 68/300\n",
            "1000/1000 [==============================] - 1s 819us/step - loss: 0.0836 - acc: 0.9566\n",
            "Epoch 69/300\n",
            "1000/1000 [==============================] - 1s 825us/step - loss: 0.0790 - acc: 0.9583\n",
            "Epoch 70/300\n",
            "1000/1000 [==============================] - 1s 820us/step - loss: 0.0841 - acc: 0.9564\n",
            "Epoch 71/300\n",
            "1000/1000 [==============================] - 1s 823us/step - loss: 0.0763 - acc: 0.9597\n",
            "Epoch 72/300\n",
            "1000/1000 [==============================] - 1s 822us/step - loss: 0.0758 - acc: 0.9596\n",
            "Epoch 73/300\n",
            "1000/1000 [==============================] - 1s 815us/step - loss: 0.0771 - acc: 0.9597\n",
            "Epoch 74/300\n",
            "1000/1000 [==============================] - 1s 818us/step - loss: 0.0795 - acc: 0.9585\n",
            "Epoch 75/300\n",
            "1000/1000 [==============================] - 1s 814us/step - loss: 0.0735 - acc: 0.9611\n",
            "Epoch 76/300\n",
            "1000/1000 [==============================] - 1s 828us/step - loss: 0.0765 - acc: 0.9600\n",
            "Epoch 77/300\n",
            "1000/1000 [==============================] - 1s 831us/step - loss: 0.0722 - acc: 0.9620\n",
            "Epoch 78/300\n",
            "1000/1000 [==============================] - 1s 826us/step - loss: 0.0649 - acc: 0.9649\n",
            "Epoch 79/300\n",
            "1000/1000 [==============================] - 1s 826us/step - loss: 0.0721 - acc: 0.9623\n",
            "Epoch 80/300\n",
            "1000/1000 [==============================] - 1s 822us/step - loss: 0.0699 - acc: 0.9633\n",
            "Epoch 81/300\n",
            "1000/1000 [==============================] - 1s 825us/step - loss: 0.0684 - acc: 0.9641\n",
            "Epoch 82/300\n",
            "1000/1000 [==============================] - 1s 823us/step - loss: 0.0711 - acc: 0.9629\n",
            "Epoch 83/300\n",
            "1000/1000 [==============================] - 1s 825us/step - loss: 0.0678 - acc: 0.9644\n",
            "Epoch 84/300\n",
            "1000/1000 [==============================] - 1s 828us/step - loss: 0.0721 - acc: 0.9626\n",
            "Epoch 85/300\n",
            "1000/1000 [==============================] - 1s 821us/step - loss: 0.0667 - acc: 0.9650\n",
            "Epoch 86/300\n",
            "1000/1000 [==============================] - 1s 820us/step - loss: 0.0695 - acc: 0.9640\n",
            "Epoch 87/300\n",
            "1000/1000 [==============================] - 1s 830us/step - loss: 0.0620 - acc: 0.9670\n",
            "Epoch 88/300\n",
            "1000/1000 [==============================] - 1s 828us/step - loss: 0.0625 - acc: 0.9672\n",
            "Epoch 89/300\n",
            "1000/1000 [==============================] - 1s 824us/step - loss: 0.0617 - acc: 0.9671\n",
            "Epoch 90/300\n",
            "1000/1000 [==============================] - 1s 822us/step - loss: 0.0692 - acc: 0.9648\n",
            "Epoch 91/300\n",
            "1000/1000 [==============================] - 1s 823us/step - loss: 0.0574 - acc: 0.9692\n",
            "Epoch 92/300\n",
            "1000/1000 [==============================] - 1s 824us/step - loss: 0.0615 - acc: 0.9675\n",
            "Epoch 93/300\n",
            "1000/1000 [==============================] - 1s 822us/step - loss: 0.0597 - acc: 0.9684\n",
            "Epoch 94/300\n",
            "1000/1000 [==============================] - 1s 830us/step - loss: 0.0591 - acc: 0.9683\n",
            "Epoch 95/300\n",
            "1000/1000 [==============================] - 1s 817us/step - loss: 0.0593 - acc: 0.9689\n",
            "Epoch 96/300\n",
            "1000/1000 [==============================] - 1s 822us/step - loss: 0.0577 - acc: 0.9692\n",
            "Epoch 97/300\n",
            "1000/1000 [==============================] - 1s 825us/step - loss: 0.0557 - acc: 0.9700\n",
            "Epoch 98/300\n",
            "1000/1000 [==============================] - 1s 821us/step - loss: 0.0570 - acc: 0.9698\n",
            "Epoch 99/300\n",
            "1000/1000 [==============================] - 1s 818us/step - loss: 0.0540 - acc: 0.9713\n",
            "Epoch 100/300\n",
            "1000/1000 [==============================] - 1s 832us/step - loss: 0.0564 - acc: 0.9701\n",
            "Epoch 101/300\n",
            "1000/1000 [==============================] - 1s 824us/step - loss: 0.0586 - acc: 0.9689\n",
            "Epoch 102/300\n",
            "1000/1000 [==============================] - 1s 828us/step - loss: 0.0540 - acc: 0.9712\n",
            "Epoch 103/300\n",
            "1000/1000 [==============================] - 1s 824us/step - loss: 0.0526 - acc: 0.9718\n",
            "Epoch 104/300\n",
            "1000/1000 [==============================] - 1s 824us/step - loss: 0.0533 - acc: 0.9715\n",
            "Epoch 105/300\n",
            "1000/1000 [==============================] - 1s 833us/step - loss: 0.0526 - acc: 0.9721\n",
            "Epoch 106/300\n",
            "1000/1000 [==============================] - 1s 836us/step - loss: 0.0502 - acc: 0.9729\n",
            "Epoch 107/300\n",
            "1000/1000 [==============================] - 1s 832us/step - loss: 0.0475 - acc: 0.9740\n",
            "Epoch 108/300\n",
            "1000/1000 [==============================] - 1s 829us/step - loss: 0.0580 - acc: 0.9704\n",
            "Epoch 109/300\n",
            "1000/1000 [==============================] - 1s 831us/step - loss: 0.0504 - acc: 0.9730\n",
            "Epoch 110/300\n",
            "1000/1000 [==============================] - 1s 831us/step - loss: 0.0547 - acc: 0.9714\n",
            "Epoch 111/300\n",
            "1000/1000 [==============================] - 1s 827us/step - loss: 0.0519 - acc: 0.9722\n",
            "Epoch 112/300\n",
            "1000/1000 [==============================] - 1s 833us/step - loss: 0.0495 - acc: 0.9735\n",
            "Epoch 113/300\n",
            "1000/1000 [==============================] - 1s 832us/step - loss: 0.0413 - acc: 0.9768\n",
            "Epoch 114/300\n",
            "1000/1000 [==============================] - 1s 827us/step - loss: 0.0451 - acc: 0.9755\n",
            "Epoch 115/300\n",
            "1000/1000 [==============================] - 1s 822us/step - loss: 0.0512 - acc: 0.9727\n",
            "Epoch 116/300\n",
            "1000/1000 [==============================] - 1s 825us/step - loss: 0.0452 - acc: 0.9755\n",
            "Epoch 117/300\n",
            "1000/1000 [==============================] - 1s 830us/step - loss: 0.0468 - acc: 0.9747\n",
            "Epoch 118/300\n",
            "1000/1000 [==============================] - 1s 825us/step - loss: 0.0510 - acc: 0.9735\n",
            "Epoch 119/300\n",
            "1000/1000 [==============================] - 1s 830us/step - loss: 0.0384 - acc: 0.9783\n",
            "Epoch 120/300\n",
            "1000/1000 [==============================] - 1s 823us/step - loss: 0.0423 - acc: 0.9766\n",
            "Epoch 121/300\n",
            "1000/1000 [==============================] - 1s 827us/step - loss: 0.0385 - acc: 0.9786\n",
            "Epoch 122/300\n",
            "1000/1000 [==============================] - 1s 831us/step - loss: 0.0495 - acc: 0.9738\n",
            "Epoch 123/300\n",
            "1000/1000 [==============================] - 1s 833us/step - loss: 0.0316 - acc: 0.9814\n",
            "Epoch 124/300\n",
            "1000/1000 [==============================] - 1s 830us/step - loss: 0.0410 - acc: 0.9777\n",
            "Epoch 125/300\n",
            "1000/1000 [==============================] - 1s 826us/step - loss: 0.0460 - acc: 0.9756\n",
            "Epoch 126/300\n",
            "1000/1000 [==============================] - 1s 832us/step - loss: 0.0412 - acc: 0.9778\n",
            "Epoch 127/300\n",
            "1000/1000 [==============================] - 1s 831us/step - loss: 0.0366 - acc: 0.9793\n",
            "Epoch 128/300\n",
            "1000/1000 [==============================] - 1s 828us/step - loss: 0.0432 - acc: 0.9768\n",
            "Epoch 129/300\n",
            "1000/1000 [==============================] - 1s 829us/step - loss: 0.0382 - acc: 0.9786\n",
            "Epoch 130/300\n",
            "1000/1000 [==============================] - 1s 836us/step - loss: 0.0271 - acc: 0.9835\n",
            "Epoch 131/300\n",
            "1000/1000 [==============================] - 1s 835us/step - loss: 0.0414 - acc: 0.9779\n",
            "Epoch 132/300\n",
            "1000/1000 [==============================] - 1s 830us/step - loss: 0.0405 - acc: 0.9783\n",
            "Epoch 133/300\n",
            "1000/1000 [==============================] - 1s 828us/step - loss: 0.0395 - acc: 0.9783\n",
            "Epoch 134/300\n",
            "1000/1000 [==============================] - 1s 830us/step - loss: 0.0372 - acc: 0.9794\n",
            "Epoch 135/300\n",
            "1000/1000 [==============================] - 1s 830us/step - loss: 0.0359 - acc: 0.9799\n",
            "Epoch 136/300\n",
            "1000/1000 [==============================] - 1s 832us/step - loss: 0.0248 - acc: 0.9850\n",
            "Epoch 137/300\n",
            "1000/1000 [==============================] - 1s 831us/step - loss: 0.0326 - acc: 0.9815\n",
            "Epoch 138/300\n",
            "1000/1000 [==============================] - 1s 832us/step - loss: 0.0367 - acc: 0.9797\n",
            "Epoch 139/300\n",
            "1000/1000 [==============================] - 1s 830us/step - loss: 0.0367 - acc: 0.9795\n",
            "Epoch 140/300\n",
            "1000/1000 [==============================] - 1s 834us/step - loss: 0.0313 - acc: 0.9821\n",
            "Epoch 141/300\n",
            "1000/1000 [==============================] - 1s 834us/step - loss: 0.0327 - acc: 0.9816\n",
            "Epoch 142/300\n",
            "1000/1000 [==============================] - 1s 837us/step - loss: 0.0309 - acc: 0.9824\n",
            "Epoch 143/300\n",
            "1000/1000 [==============================] - 1s 830us/step - loss: 0.0347 - acc: 0.9808\n",
            "Epoch 144/300\n",
            "1000/1000 [==============================] - 1s 841us/step - loss: 0.0290 - acc: 0.9829\n",
            "Epoch 145/300\n",
            "1000/1000 [==============================] - 1s 841us/step - loss: 0.0329 - acc: 0.9815\n",
            "Epoch 146/300\n",
            "1000/1000 [==============================] - 1s 843us/step - loss: 0.0300 - acc: 0.9830\n",
            "Epoch 147/300\n",
            "1000/1000 [==============================] - 1s 838us/step - loss: 0.0325 - acc: 0.9816\n",
            "Epoch 148/300\n",
            "1000/1000 [==============================] - 1s 839us/step - loss: 0.0269 - acc: 0.9839\n",
            "Epoch 149/300\n",
            "1000/1000 [==============================] - 1s 835us/step - loss: 0.0260 - acc: 0.9849\n",
            "Epoch 150/300\n",
            "1000/1000 [==============================] - 1s 838us/step - loss: 0.0286 - acc: 0.9840\n",
            "Epoch 151/300\n",
            "1000/1000 [==============================] - 1s 833us/step - loss: 0.0393 - acc: 0.9791\n",
            "Epoch 152/300\n",
            "1000/1000 [==============================] - 1s 830us/step - loss: 0.0322 - acc: 0.9820\n",
            "Epoch 153/300\n",
            "1000/1000 [==============================] - 1s 836us/step - loss: 0.0344 - acc: 0.9813\n",
            "Epoch 154/300\n",
            "1000/1000 [==============================] - 1s 835us/step - loss: 0.0309 - acc: 0.9825\n",
            "Epoch 155/300\n",
            "1000/1000 [==============================] - 1s 832us/step - loss: 0.0262 - acc: 0.9846\n",
            "Epoch 156/300\n",
            "1000/1000 [==============================] - 1s 838us/step - loss: 0.0283 - acc: 0.9835\n",
            "Epoch 157/300\n",
            "1000/1000 [==============================] - 1s 838us/step - loss: 0.0238 - acc: 0.9858\n",
            "Epoch 158/300\n",
            "1000/1000 [==============================] - 1s 836us/step - loss: 0.0207 - acc: 0.9870\n",
            "Epoch 159/300\n",
            "1000/1000 [==============================] - 1s 840us/step - loss: 0.0262 - acc: 0.9849\n",
            "Epoch 160/300\n",
            "1000/1000 [==============================] - 1s 833us/step - loss: 0.0317 - acc: 0.9826\n",
            "Epoch 161/300\n",
            "1000/1000 [==============================] - 1s 834us/step - loss: 0.0195 - acc: 0.9878\n",
            "Epoch 162/300\n",
            "1000/1000 [==============================] - 1s 833us/step - loss: 0.0298 - acc: 0.9835\n",
            "Epoch 163/300\n",
            "1000/1000 [==============================] - 1s 837us/step - loss: 0.0260 - acc: 0.9851\n",
            "Epoch 164/300\n",
            "1000/1000 [==============================] - 1s 842us/step - loss: 0.0309 - acc: 0.9830\n",
            "Epoch 165/300\n",
            "1000/1000 [==============================] - 1s 837us/step - loss: 0.0232 - acc: 0.9864\n",
            "Epoch 166/300\n",
            "1000/1000 [==============================] - 1s 831us/step - loss: 0.0284 - acc: 0.9839\n",
            "Epoch 167/300\n",
            "1000/1000 [==============================] - 1s 838us/step - loss: 0.0280 - acc: 0.9847\n",
            "Epoch 168/300\n",
            "1000/1000 [==============================] - 1s 833us/step - loss: 0.0237 - acc: 0.9861\n",
            "Epoch 169/300\n",
            "1000/1000 [==============================] - 1s 838us/step - loss: 0.0159 - acc: 0.9896\n",
            "Epoch 170/300\n",
            "1000/1000 [==============================] - 1s 847us/step - loss: 0.0227 - acc: 0.9869\n",
            "Epoch 171/300\n",
            "1000/1000 [==============================] - 1s 836us/step - loss: 0.0292 - acc: 0.9838\n",
            "Epoch 172/300\n",
            "1000/1000 [==============================] - 1s 842us/step - loss: 0.0188 - acc: 0.9883\n",
            "Epoch 173/300\n",
            "1000/1000 [==============================] - 1s 840us/step - loss: 0.0155 - acc: 0.9899\n",
            "Epoch 174/300\n",
            "1000/1000 [==============================] - 1s 845us/step - loss: 0.0285 - acc: 0.9843\n",
            "Epoch 175/300\n",
            "1000/1000 [==============================] - 1s 834us/step - loss: 0.0174 - acc: 0.9889\n",
            "Epoch 176/300\n",
            "1000/1000 [==============================] - 1s 842us/step - loss: 0.0150 - acc: 0.9903\n",
            "Epoch 177/300\n",
            "1000/1000 [==============================] - 1s 834us/step - loss: 0.0271 - acc: 0.9854\n",
            "Epoch 178/300\n",
            "1000/1000 [==============================] - 1s 835us/step - loss: 0.0233 - acc: 0.9867\n",
            "Epoch 179/300\n",
            "1000/1000 [==============================] - 1s 838us/step - loss: 0.0162 - acc: 0.9898\n",
            "Epoch 180/300\n",
            "1000/1000 [==============================] - 1s 835us/step - loss: 0.0192 - acc: 0.9886\n",
            "Epoch 181/300\n",
            "1000/1000 [==============================] - 1s 839us/step - loss: 0.0236 - acc: 0.9864\n",
            "Epoch 182/300\n",
            "1000/1000 [==============================] - 1s 839us/step - loss: 0.0216 - acc: 0.9873\n",
            "Epoch 183/300\n",
            "1000/1000 [==============================] - 1s 836us/step - loss: 0.0149 - acc: 0.9903\n",
            "Epoch 184/300\n",
            "1000/1000 [==============================] - 1s 843us/step - loss: 0.0129 - acc: 0.9916\n",
            "Epoch 185/300\n",
            "1000/1000 [==============================] - 1s 839us/step - loss: 0.0183 - acc: 0.9892\n",
            "Epoch 186/300\n",
            "1000/1000 [==============================] - 1s 846us/step - loss: 0.0285 - acc: 0.9846\n",
            "Epoch 187/300\n",
            "1000/1000 [==============================] - 1s 844us/step - loss: 0.0261 - acc: 0.9856\n",
            "Epoch 188/300\n",
            "1000/1000 [==============================] - 1s 839us/step - loss: 0.0143 - acc: 0.9907\n",
            "Epoch 189/300\n",
            "1000/1000 [==============================] - 1s 838us/step - loss: 0.0167 - acc: 0.9897\n",
            "Epoch 190/300\n",
            "1000/1000 [==============================] - 1s 839us/step - loss: 0.0231 - acc: 0.9867\n",
            "Epoch 191/300\n",
            "1000/1000 [==============================] - 1s 842us/step - loss: 0.0264 - acc: 0.9856\n",
            "Epoch 192/300\n",
            "1000/1000 [==============================] - 1s 836us/step - loss: 0.0116 - acc: 0.9923\n",
            "Epoch 193/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0148 - acc: 0.9906\n",
            "Epoch 194/300\n",
            "1000/1000 [==============================] - 1s 843us/step - loss: 0.0215 - acc: 0.9876\n",
            "Epoch 195/300\n",
            "1000/1000 [==============================] - 1s 838us/step - loss: 0.0214 - acc: 0.9881\n",
            "Epoch 196/300\n",
            "1000/1000 [==============================] - 1s 839us/step - loss: 0.0124 - acc: 0.9919\n",
            "Epoch 197/300\n",
            "1000/1000 [==============================] - 1s 846us/step - loss: 0.0179 - acc: 0.9892\n",
            "Epoch 198/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0120 - acc: 0.9920\n",
            "Epoch 199/300\n",
            "1000/1000 [==============================] - 1s 844us/step - loss: 0.0238 - acc: 0.9872\n",
            "Epoch 200/300\n",
            "1000/1000 [==============================] - 1s 836us/step - loss: 0.0108 - acc: 0.9929\n",
            "Epoch 201/300\n",
            "1000/1000 [==============================] - 1s 840us/step - loss: 0.0107 - acc: 0.9931\n",
            "Epoch 202/300\n",
            "1000/1000 [==============================] - 1s 850us/step - loss: 0.0140 - acc: 0.9912\n",
            "Epoch 203/300\n",
            "1000/1000 [==============================] - 1s 845us/step - loss: 0.0099 - acc: 0.9934\n",
            "Epoch 204/300\n",
            "1000/1000 [==============================] - 1s 848us/step - loss: 0.0201 - acc: 0.9887\n",
            "Epoch 205/300\n",
            "1000/1000 [==============================] - 1s 845us/step - loss: 0.0109 - acc: 0.9928\n",
            "Epoch 206/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0104 - acc: 0.9934\n",
            "Epoch 207/300\n",
            "1000/1000 [==============================] - 1s 846us/step - loss: 0.0225 - acc: 0.9878\n",
            "Epoch 208/300\n",
            "1000/1000 [==============================] - 1s 844us/step - loss: 0.0089 - acc: 0.9940\n",
            "Epoch 209/300\n",
            "1000/1000 [==============================] - 1s 851us/step - loss: 0.0087 - acc: 0.9941\n",
            "Epoch 210/300\n",
            "1000/1000 [==============================] - 1s 842us/step - loss: 0.0187 - acc: 0.9898\n",
            "Epoch 211/300\n",
            "1000/1000 [==============================] - 1s 842us/step - loss: 0.0123 - acc: 0.9923\n",
            "Epoch 212/300\n",
            "1000/1000 [==============================] - 1s 841us/step - loss: 0.0090 - acc: 0.9939\n",
            "Epoch 213/300\n",
            "1000/1000 [==============================] - 1s 845us/step - loss: 0.0091 - acc: 0.9939\n",
            "Epoch 214/300\n",
            "1000/1000 [==============================] - 1s 843us/step - loss: 0.0207 - acc: 0.9885\n",
            "Epoch 215/300\n",
            "1000/1000 [==============================] - 1s 844us/step - loss: 0.0103 - acc: 0.9931\n",
            "Epoch 216/300\n",
            "1000/1000 [==============================] - 1s 846us/step - loss: 0.0078 - acc: 0.9947\n",
            "Epoch 217/300\n",
            "1000/1000 [==============================] - 1s 848us/step - loss: 0.0189 - acc: 0.9900\n",
            "Epoch 218/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0105 - acc: 0.9931\n",
            "Epoch 219/300\n",
            "1000/1000 [==============================] - 1s 841us/step - loss: 0.0083 - acc: 0.9945\n",
            "Epoch 220/300\n",
            "1000/1000 [==============================] - 1s 842us/step - loss: 0.0089 - acc: 0.9940\n",
            "Epoch 221/300\n",
            "1000/1000 [==============================] - 1s 837us/step - loss: 0.0074 - acc: 0.9950\n",
            "Epoch 222/300\n",
            "1000/1000 [==============================] - 1s 838us/step - loss: 0.0074 - acc: 0.9949\n",
            "Epoch 223/300\n",
            "1000/1000 [==============================] - 1s 853us/step - loss: 0.0203 - acc: 0.9890\n",
            "Epoch 224/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0218 - acc: 0.9879\n",
            "Epoch 225/300\n",
            "1000/1000 [==============================] - 1s 851us/step - loss: 0.0087 - acc: 0.9940\n",
            "Epoch 226/300\n",
            "1000/1000 [==============================] - 1s 847us/step - loss: 0.0074 - acc: 0.9949\n",
            "Epoch 227/300\n",
            "1000/1000 [==============================] - 1s 851us/step - loss: 0.0068 - acc: 0.9953\n",
            "Epoch 228/300\n",
            "1000/1000 [==============================] - 1s 848us/step - loss: 0.0236 - acc: 0.9879\n",
            "Epoch 229/300\n",
            "1000/1000 [==============================] - 1s 846us/step - loss: 0.0088 - acc: 0.9943\n",
            "Epoch 230/300\n",
            "1000/1000 [==============================] - 1s 844us/step - loss: 0.0179 - acc: 0.9897\n",
            "Epoch 231/300\n",
            "1000/1000 [==============================] - 1s 848us/step - loss: 0.0073 - acc: 0.9949\n",
            "Epoch 232/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0080 - acc: 0.9947\n",
            "Epoch 233/300\n",
            "1000/1000 [==============================] - 1s 842us/step - loss: 0.0228 - acc: 0.9878\n",
            "Epoch 234/300\n",
            "1000/1000 [==============================] - 1s 846us/step - loss: 0.0225 - acc: 0.9882\n",
            "Epoch 235/300\n",
            "1000/1000 [==============================] - 1s 848us/step - loss: 0.0151 - acc: 0.9912\n",
            "Epoch 236/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0071 - acc: 0.9951\n",
            "Epoch 237/300\n",
            "1000/1000 [==============================] - 1s 841us/step - loss: 0.0064 - acc: 0.9955\n",
            "Epoch 238/300\n",
            "1000/1000 [==============================] - 1s 847us/step - loss: 0.0164 - acc: 0.9907\n",
            "Epoch 239/300\n",
            "1000/1000 [==============================] - 1s 848us/step - loss: 0.0122 - acc: 0.9923\n",
            "Epoch 240/300\n",
            "1000/1000 [==============================] - 1s 848us/step - loss: 0.0064 - acc: 0.9956\n",
            "Epoch 241/300\n",
            "1000/1000 [==============================] - 1s 844us/step - loss: 0.0074 - acc: 0.9949\n",
            "Epoch 242/300\n",
            "1000/1000 [==============================] - 1s 846us/step - loss: 0.0065 - acc: 0.9954\n",
            "Epoch 243/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0061 - acc: 0.9959\n",
            "Epoch 244/300\n",
            "1000/1000 [==============================] - 1s 842us/step - loss: 0.0172 - acc: 0.9903\n",
            "Epoch 245/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0163 - acc: 0.9908\n",
            "Epoch 246/300\n",
            "1000/1000 [==============================] - 1s 848us/step - loss: 0.0145 - acc: 0.9912\n",
            "Epoch 247/300\n",
            "1000/1000 [==============================] - 1s 843us/step - loss: 0.0087 - acc: 0.9946\n",
            "Epoch 248/300\n",
            "1000/1000 [==============================] - 1s 842us/step - loss: 0.0058 - acc: 0.9961\n",
            "Epoch 249/300\n",
            "1000/1000 [==============================] - 1s 851us/step - loss: 0.0062 - acc: 0.9957\n",
            "Epoch 250/300\n",
            "1000/1000 [==============================] - 1s 842us/step - loss: 0.0182 - acc: 0.9901\n",
            "Epoch 251/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0195 - acc: 0.9894\n",
            "Epoch 252/300\n",
            "1000/1000 [==============================] - 1s 845us/step - loss: 0.0069 - acc: 0.9956\n",
            "Epoch 253/300\n",
            "1000/1000 [==============================] - 1s 843us/step - loss: 0.0071 - acc: 0.9952\n",
            "Epoch 254/300\n",
            "1000/1000 [==============================] - 1s 841us/step - loss: 0.0057 - acc: 0.9961\n",
            "Epoch 255/300\n",
            "1000/1000 [==============================] - 1s 839us/step - loss: 0.0055 - acc: 0.9963\n",
            "Epoch 256/300\n",
            "1000/1000 [==============================] - 1s 845us/step - loss: 0.0055 - acc: 0.9963\n",
            "Epoch 257/300\n",
            "1000/1000 [==============================] - 1s 850us/step - loss: 0.0050 - acc: 0.9966\n",
            "Epoch 258/300\n",
            "1000/1000 [==============================] - 1s 841us/step - loss: 0.0050 - acc: 0.9966\n",
            "Epoch 259/300\n",
            "1000/1000 [==============================] - 1s 844us/step - loss: 0.0175 - acc: 0.9911\n",
            "Epoch 260/300\n",
            "1000/1000 [==============================] - 1s 841us/step - loss: 0.0210 - acc: 0.9890\n",
            "Epoch 261/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0060 - acc: 0.9958\n",
            "Epoch 262/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0051 - acc: 0.9966\n",
            "Epoch 263/300\n",
            "1000/1000 [==============================] - 1s 845us/step - loss: 0.0049 - acc: 0.9968\n",
            "Epoch 264/300\n",
            "1000/1000 [==============================] - 1s 854us/step - loss: 0.0052 - acc: 0.9966\n",
            "Epoch 265/300\n",
            "1000/1000 [==============================] - 1s 842us/step - loss: 0.0197 - acc: 0.9899\n",
            "Epoch 266/300\n",
            "1000/1000 [==============================] - 1s 842us/step - loss: 0.0052 - acc: 0.9964\n",
            "Epoch 267/300\n",
            "1000/1000 [==============================] - 1s 850us/step - loss: 0.0052 - acc: 0.9964\n",
            "Epoch 268/300\n",
            "1000/1000 [==============================] - 1s 852us/step - loss: 0.0046 - acc: 0.9969\n",
            "Epoch 269/300\n",
            "1000/1000 [==============================] - 1s 848us/step - loss: 0.0046 - acc: 0.9969\n",
            "Epoch 270/300\n",
            "1000/1000 [==============================] - 1s 852us/step - loss: 0.0046 - acc: 0.9970\n",
            "Epoch 271/300\n",
            "1000/1000 [==============================] - 1s 852us/step - loss: 0.0046 - acc: 0.9969\n",
            "Epoch 272/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0157 - acc: 0.9915\n",
            "Epoch 273/300\n",
            "1000/1000 [==============================] - 1s 854us/step - loss: 0.0167 - acc: 0.9914\n",
            "Epoch 274/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0173 - acc: 0.9909\n",
            "Epoch 275/300\n",
            "1000/1000 [==============================] - 1s 847us/step - loss: 0.0054 - acc: 0.9963\n",
            "Epoch 276/300\n",
            "1000/1000 [==============================] - 1s 853us/step - loss: 0.0049 - acc: 0.9967\n",
            "Epoch 277/300\n",
            "1000/1000 [==============================] - 1s 851us/step - loss: 0.0047 - acc: 0.9969\n",
            "Epoch 278/300\n",
            "1000/1000 [==============================] - 1s 853us/step - loss: 0.0048 - acc: 0.9968\n",
            "Epoch 279/300\n",
            "1000/1000 [==============================] - 1s 846us/step - loss: 0.0043 - acc: 0.9972\n",
            "Epoch 280/300\n",
            "1000/1000 [==============================] - 1s 843us/step - loss: 0.0084 - acc: 0.9952\n",
            "Epoch 281/300\n",
            "1000/1000 [==============================] - 1s 846us/step - loss: 0.0257 - acc: 0.9875\n",
            "Epoch 282/300\n",
            "1000/1000 [==============================] - 1s 850us/step - loss: 0.0078 - acc: 0.9952\n",
            "Epoch 283/300\n",
            "1000/1000 [==============================] - 1s 843us/step - loss: 0.0135 - acc: 0.9926\n",
            "Epoch 284/300\n",
            "1000/1000 [==============================] - 1s 846us/step - loss: 0.0047 - acc: 0.9969\n",
            "Epoch 285/300\n",
            "1000/1000 [==============================] - 1s 843us/step - loss: 0.0045 - acc: 0.9971\n",
            "Epoch 286/300\n",
            "1000/1000 [==============================] - 1s 852us/step - loss: 0.0049 - acc: 0.9968\n",
            "Epoch 287/300\n",
            "1000/1000 [==============================] - 1s 847us/step - loss: 0.0043 - acc: 0.9972\n",
            "Epoch 288/300\n",
            "1000/1000 [==============================] - 1s 854us/step - loss: 0.0041 - acc: 0.9974\n",
            "Epoch 289/300\n",
            "1000/1000 [==============================] - 1s 852us/step - loss: 0.0042 - acc: 0.9973\n",
            "Epoch 290/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0040 - acc: 0.9974\n",
            "Epoch 291/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0093 - acc: 0.9949\n",
            "Epoch 292/300\n",
            "1000/1000 [==============================] - 1s 848us/step - loss: 0.0150 - acc: 0.9924\n",
            "Epoch 293/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0051 - acc: 0.9968\n",
            "Epoch 294/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0049 - acc: 0.9969\n",
            "Epoch 295/300\n",
            "1000/1000 [==============================] - 1s 857us/step - loss: 0.0039 - acc: 0.9974\n",
            "Epoch 296/300\n",
            "1000/1000 [==============================] - 1s 853us/step - loss: 0.0039 - acc: 0.9975\n",
            "Epoch 297/300\n",
            "1000/1000 [==============================] - 1s 846us/step - loss: 0.0064 - acc: 0.9960\n",
            "Epoch 298/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0041 - acc: 0.9972\n",
            "Epoch 299/300\n",
            "1000/1000 [==============================] - 1s 847us/step - loss: 0.0038 - acc: 0.9976\n",
            "Epoch 300/300\n",
            "1000/1000 [==============================] - 1s 849us/step - loss: 0.0036 - acc: 0.9977\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f415964e8d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BA0vit4aey23",
        "outputId": "7a80aa94-baab-476c-c097-80e645f5976f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 781
        }
      },
      "source": [
        "H6=rnvide5.predict(L1, batch_size=None, verbose=0, steps=None, callbacks=None, max_queue_size=10, workers=1, use_multiprocessing=False)\n",
        "\n",
        "H7=np.around(H6) # work\n",
        "\n",
        "t=rd.randint (0,1001)\n",
        "print(t)\n",
        "\n",
        "im3300 = MtoIm(L1[t],30) # We visually compare the precondition and the final result\n",
        "plt.imshow(im3300)\n",
        "plt.show()\n",
        "\n",
        "im3400 = MtoIm(L50[t],30)\n",
        "plt.imshow(im3400)\n",
        "plt.show()\n",
        "\n",
        "im35000 = MtoIm(H7[t],30)\n",
        "plt.imshow(im35000)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAMKElEQVR4nO3dT6il9X3H8fen1mzUxVjtMBhbU3ET\nAh3rRQqRYgkJ1o26kbgIFoTJIoJCFpV0EZdSoqErwVTJtKSGgBElSBMrgmQj3pGpjk4brYxkhtFR\nXGhWqebbxX0sN9N7z72ef8+59/t+wcM55znn3Od7f/d87vOc832e56SqkLT//cHYBUhaDsMuNWHY\npSYMu9SEYZeaMOxSE384y5OT3AT8I3AB8E9V9cDEx1+W4qpZlrj/XXds+cs8dt3yl6kFOQX1fmWr\nuzJtnz3JBcCvgK8Cp4GXgDuq6vVtn7OWYn2qxbWx9Z9pseKuFvvHGtT61q+iWTbjrwferKq3quq3\nwI+BW2b4eZIWaJawXwH8etPt08M8SSto4R/QJTmSZD3JOu8temmStjNL2M8AV266/flh3u+pqkeq\naq2q1rh8hqVJmsksYX8JuCbJF5J8Dvg68PR8ypI0b1O33qrq4yR3Az9no/X2WFW9NrfKJM3VTH32\nqnoGeGZOtUhaIPegk5ow7FIThl1qwrBLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHap\niZmOetNnN8oJJZe/yNFMO74dTrrpml1qwrBLTRh2qQnDLjVh2KUmDLvUxFJbb9cdg3VbI8u318Zu\nwmtkUb/KpJbdfnntuWaXmjDsUhOGXWrCsEtNGHapCcMuNTFT6y3JKeAj4BPg46pam0dRW9lLrZEx\njmxbRY7DaplHn/2vq+r9OfwcSQvkZrzUxKxhL+AXSY4lOTKPgiQtxqyb8TdU1Zkkfww8m+Q/q+qF\nzQ8Y/gkcAfiTGRcmaXozrdmr6sxweQ54Erh+i8c8UlVrVbV2+SwLkzSTqcOe5KIkl3x6HfgacGJe\nhUmar1k24w8CTyb59Of8a1X921yqkjR3U4e9qt4C/nyOtewtK9ZDHmNfg/3UR1+1fTUWwdab1IRh\nl5ow7FIThl1qwrBLTRh2qQm/2HFKY3Rq9lGnaxQd2muTuGaXmjDsUhOGXWrCsEtNGHapCcMuNWHr\nbS9p3jrSbFyzS00YdqkJwy41YdilJgy71IRhl5rYM6237kcsraKd/iardkLKvfTloIvgml1qwrBL\nTRh2qQnDLjVh2KUmDLvUhGGXmtgx7EkeS3IuyYlN8y5N8mySN4bLA7tZ2LHrNvqZ00yrJhMmbdhL\nf8/KYqZVsps1+w+Bm86bdx/wXFVdAzw33Ja0wnYMe1W9AHxw3uxbgKPD9aPArXOuS9KcTfue/WBV\nnR2uvwMc3O6BSY4kWU+yzntTLk3SzGb+gK6qigknTKqqR6pqrarWuHzWpUma1rRhfzfJIYDh8tz8\nSpK0CNOG/WngzuH6ncBT8ylH0qLseIhrkseBG4HLkpwGvgs8APwkyV3A28DtiyxyJU1qH83Qclmx\nbs3CTGq/rVrLahardFjtjmGvqju2uesrc65F0gK5B53UhGGXmjDsUhOGXWrCsEtN7Jmzy7axgkeE\nLVuXttzEPusCXgeu2aUmDLvUhGGXmjDsUhOGXWrCsEtN2Hqb0n5qAU37u4xx4si99mWSkyzowMlt\nuWaXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSZa99n3Uk92Fov6PRf1c2fp37c5PHYKrtmlJgy71IRh\nl5ow7FIThl1qwrBLTewY9iSPJTmX5MSmefcnOZPk+DDdvNgyp1fZfhpDavKkxf3NVm3cl13Pbtbs\nPwRu2mL+96vq8DA9M9+yJM3bjmGvqheAD5ZQi6QFmuU9+91JXhk28w/MrSJJCzFt2B8GrgYOA2eB\nB7d7YJIjSdaTrPPelEuTNLOpwl5V71bVJ1X1O+AHwPUTHvtIVa1V1RqXT1umpFlNFfYkhzbdvA04\nsd1jJa2GHY96S/I4cCNwWZLTwHeBG5McZuMEmaeAby6wxpVkm2wcO7Xfpv27LOpouVV6newY9qq6\nY4vZjy6gFkkL5B50UhOGXWrCsEtNGHapCcMuNWHYpSZan112J6vUI91J9zOnfmrSOCyiB7+XuGaX\nmjDsUhOGXWrCsEtNGHapCcMuNbEvWm/7qe20n34XrRbX7FIThl1qwrBLTRh2qQnDLjVh2KUm9kXr\nbVEWcQSVrTWNxTW71IRhl5ow7FIThl1qwrBLTRh2qYkdw57kyiTPJ3k9yWtJ7hnmX5rk2SRvDJcH\nFl/u6qhMN2mxUttP3e1mzf4x8O2q+iLwl8C3knwRuA94rqquAZ4bbktaUTuGvarOVtXLw/WPgJPA\nFcAtwNHhYUeBWxdVpKTZfab37EmuAq4FXgQOVtXZ4a53gINzrUzSXO067EkuBp4A7q2qDzffV1UF\nbPmuKMmRJOtJ1nlvplolzWBXYU9yIRtB/1FV/XSY/W6SQ8P9h4BzWz23qh6pqrWqWuPyeZQsaRq7\n+TQ+wKPAyap6aNNdTwN3DtfvBJ6af3mS5mU3R719GfgG8GqS48O87wAPAD9JchfwNnD7YkqUNA87\nhr2qfgls1yH+ynzLmc6kHqq97f3Ffvn03INOasKwS00YdqkJwy41YdilJgy71MS+P7usbTlpg2t2\nqQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrCsEtNGHapCcMuNWHYpSYMu9SEYZea2PdHvU2y08kLPSpu\n9ez0N/GElNtzzS41YdilJgy71IRhl5ow7FIThl1qYjff4nplkueTvJ7ktST3DPPvT3ImyfFhunnx\n5Uqa1m767B8D366ql5NcAhxL8uxw3/er6nuLK0/SvOzmW1zPAmeH6x8lOQlcsejCJM3XZ3rPnuQq\n4FrgxWHW3UleSfJYkgNzrk3SHO067EkuBp4A7q2qD4GHgauBw2ys+R/c5nlHkqwnWee9OVQsaSqp\n2nln4iQXAj8Dfl5VD21x/1XAz6rqSxN/zlqK9ekKHYP7xu897feNX4Na3/qVu5tP4wM8CpzcHPQk\nhzY97DbgxKx1Slqc3Xwa/2XgG8CrSY4P874D3JHkMFDAKeCbC6lQ0lzs5tP4XwJbbRY8M/9yJC2K\ne9BJTRh2qQnDLjVh2KUmDLvUhGGXmmh9dlntPau4U+O0e1pOfNoC9gR0zS41YdilJgy71IRhl5ow\n7FIThl1qwtab9pYRTk6xqJOYTPxVplzm2oT7XLNLTRh2qQnDLjVh2KUmDLvUhGGXmjDsUhOGXWrC\nsEtNGHapCcMuNWHYpSYMu9SEYZea2NX3s89tYcl7wNubZl0GvL+0AnZmPZOtWj2wejWNXc+fVtXl\nW92x1LD/v4Un61U16RDcpbKeyVatHli9mlatns3cjJeaMOxSE2OH/ZGRl38+65ls1eqB1atp1er5\nP6O+Z5e0PGOv2SUtyShhT3JTkv9K8maS+8ao4bx6TiV5NcnxJOsj1fBYknNJTmyad2mSZ5O8MVwe\nGLme+5OcGcbpeJKbl1jPlUmeT/J6kteS3DPMH2WMJtQz2hjtZOmb8UkuAH4FfBU4DbwE3FFVry+1\nkN+v6RSwVlWj9UeT/BXwG+Cfq+pLw7x/AD6oqgeGf4oHqurvRqznfuA3VfW9ZdRwXj2HgENV9XKS\nS4BjwK3A3zLCGE2o53ZGGqOdjLFmvx54s6reqqrfAj8GbhmhjpVSVS8AH5w3+xbg6HD9KBsvpjHr\nGU1Vna2ql4frHwEngSsYaYwm1LOyxgj7FcCvN90+zfiDVMAvkhxLcmTkWjY7WFVnh+vvAAfHLGZw\nd5JXhs38pb2t2CzJVcC1wIuswBidVw+swBhtxQ/oNtxQVX8B/A3wrWETdqXUxvutsVsnDwNXA4eB\ns8CDyy4gycXAE8C9VfXh5vvGGKMt6hl9jLYzRtjPAFduuv35Yd5oqurMcHkOeJKNtxqr4N3hveGn\n7xHPjVlMVb1bVZ9U1e+AH7DkcUpyIRvB+lFV/XSYPdoYbVXP2GM0yRhhfwm4JskXknwO+Drw9Ah1\nAJDkouEDFpJcBHwNODH5WUvzNHDncP1O4KkRa/k0TJ+6jSWOU5IAjwInq+qhTXeNMkbb1TPmGO2o\nqpY+ATez8Yn8fwN/P0YNm2r5M+A/hum1seoBHmdjs+9/2Pgc4y7gj4DngDeAfwcuHbmefwFeBV5h\nI2SHlljPDWxsor8CHB+mm8caown1jDZGO03uQSc14Qd0UhOGXWrCsEtNGHapCcMuNWHYpSYMu9SE\nYZea+F9mo/SdimHSBQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD5CAYAAADhukOtAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n9J3Lu+0KAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ivwT9q6zeNuR"
      },
      "source": [
        ""
      ]
    }
  ]
}
